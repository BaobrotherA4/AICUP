
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-11-29 13:28:24.309954: Using torch.compile... 
2025-11-29 13:28:27.507291: do_dummy_2d_data_aug: False 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 192, 192], 'median_image_size_in_voxels': [303.0, 512.0, 512.0], 'spacing': [0.5, 0.38671875, 0.38671875], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset003_Myocardium', 'plans_name': 'nnUNetResEncUNetPlans_16G', 'original_median_spacing_after_transp': [0.5, 0.38671875, 0.38671875], 'original_median_shape_after_transp': [337, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncM', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1819.0, 'mean': 134.01280212402344, 'median': 112.0, 'min': -882.0, 'percentile_00_5': -27.0, 'percentile_99_5': 481.0, 'std': 90.67718505859375}}} 
 
2025-11-29 13:28:31.076997: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-11-29 13:28:31.142910:  
2025-11-29 13:28:31.143440: Epoch 650 
2025-11-29 13:28:31.143848: Current learning rate: 0.00137 
2025-11-29 13:30:46.901977: train_loss -0.8075 
2025-11-29 13:30:46.903833: val_loss -0.8166 
2025-11-29 13:30:46.903952: Pseudo dice [np.float32(0.9542), np.float32(0.8908)] 
2025-11-29 13:30:46.904150: Epoch time: 135.78 s 
2025-11-29 13:30:47.742853:  
2025-11-29 13:30:47.742927: Epoch 651 
2025-11-29 13:30:47.743051: Current learning rate: 0.0013 
2025-11-29 13:32:46.121398: train_loss -0.7951 
2025-11-29 13:32:46.127176: val_loss -0.8147 
2025-11-29 13:32:46.127388: Pseudo dice [np.float32(0.958), np.float32(0.8836)] 
2025-11-29 13:32:46.128375: Epoch time: 118.38 s 
2025-11-29 13:32:46.128487: Yayy! New best EMA pseudo Dice: 0.9161999821662903 
2025-11-29 13:32:47.957919:  
2025-11-29 13:32:47.958003: Epoch 652 
2025-11-29 13:32:47.958042: Current learning rate: 0.00122 
2025-11-29 13:34:45.775963: train_loss -0.8164 
2025-11-29 13:34:45.782124: val_loss -0.811 
2025-11-29 13:34:45.782239: Pseudo dice [np.float32(0.9504), np.float32(0.8681)] 
2025-11-29 13:34:45.783607: Epoch time: 117.82 s 
2025-11-29 13:34:46.546614:  
2025-11-29 13:34:46.546707: Epoch 653 
2025-11-29 13:34:46.546839: Current learning rate: 0.00116 
2025-11-29 13:36:43.752411: train_loss -0.7968 
2025-11-29 13:36:43.758946: val_loss -0.8098 
2025-11-29 13:36:43.758981: Pseudo dice [np.float32(0.9544), np.float32(0.8732)] 
2025-11-29 13:36:43.760527: Epoch time: 117.21 s 
2025-11-29 13:36:44.568474:  
2025-11-29 13:36:44.568537: Epoch 654 
2025-11-29 13:36:44.568666: Current learning rate: 0.00109 
2025-11-29 13:38:42.913842: train_loss -0.8163 
2025-11-29 13:38:42.919855: val_loss -0.8166 
2025-11-29 13:38:42.919887: Pseudo dice [np.float32(0.9509), np.float32(0.8711)] 
2025-11-29 13:38:42.921345: Epoch time: 118.35 s 
2025-11-29 13:38:47.268836:  
2025-11-29 13:38:47.268896: Epoch 655 
2025-11-29 13:38:47.268953: Current learning rate: 0.00102 
2025-11-29 13:40:44.110114: train_loss -0.7848 
2025-11-29 13:40:44.115894: val_loss -0.8337 
2025-11-29 13:40:44.116012: Pseudo dice [np.float32(0.9486), np.float32(0.8687)] 
2025-11-29 13:40:44.117491: Epoch time: 116.84 s 
2025-11-29 13:40:44.950940:  
2025-11-29 13:40:44.951052: Epoch 656 
2025-11-29 13:40:44.951185: Current learning rate: 0.00096 
2025-11-29 13:42:43.262852: train_loss -0.8121 
2025-11-29 13:42:43.269153: val_loss -0.8109 
2025-11-29 13:42:43.269290: Pseudo dice [np.float32(0.9578), np.float32(0.8922)] 
2025-11-29 13:42:43.270687: Epoch time: 118.32 s 
2025-11-29 13:42:44.083209:  
2025-11-29 13:42:44.083286: Epoch 657 
2025-11-29 13:42:44.083414: Current learning rate: 0.0009 
2025-11-29 13:44:41.377805: train_loss -0.815 
2025-11-29 13:44:41.384188: val_loss -0.8247 
2025-11-29 13:44:41.384305: Pseudo dice [np.float32(0.9584), np.float32(0.87)] 
2025-11-29 13:44:41.385575: Epoch time: 117.3 s 
2025-11-29 13:44:42.225554:  
2025-11-29 13:44:42.225652: Epoch 658 
2025-11-29 13:44:42.225785: Current learning rate: 0.00084 
2025-11-29 13:46:39.961354: train_loss -0.8079 
2025-11-29 13:46:39.967512: val_loss -0.7928 
2025-11-29 13:46:39.967601: Pseudo dice [np.float32(0.9581), np.float32(0.884)] 
2025-11-29 13:46:39.968846: Epoch time: 117.74 s 
2025-11-29 13:46:40.792640:  
2025-11-29 13:46:40.792737: Epoch 659 
2025-11-29 13:46:40.792861: Current learning rate: 0.00078 
2025-11-29 13:48:39.306535: train_loss -0.816 
2025-11-29 13:48:39.313128: val_loss -0.8265 
2025-11-29 13:48:39.313254: Pseudo dice [np.float32(0.9546), np.float32(0.8802)] 
2025-11-29 13:48:39.314794: Epoch time: 118.52 s 
2025-11-29 13:48:40.107622:  
2025-11-29 13:48:40.107705: Epoch 660 
2025-11-29 13:48:40.107849: Current learning rate: 0.00072 
2025-11-29 13:50:37.936700: train_loss -0.8055 
2025-11-29 13:50:37.942626: val_loss -0.7951 
2025-11-29 13:50:37.942744: Pseudo dice [np.float32(0.9468), np.float32(0.8606)] 
2025-11-29 13:50:37.944132: Epoch time: 117.83 s 
2025-11-29 13:50:38.723398:  
2025-11-29 13:50:38.723810: Epoch 661 
2025-11-29 13:50:38.723941: Current learning rate: 0.00067 
2025-11-29 13:52:37.439760: train_loss -0.8108 
2025-11-29 13:52:37.446428: val_loss -0.8141 
2025-11-29 13:52:37.446546: Pseudo dice [np.float32(0.9552), np.float32(0.8786)] 
2025-11-29 13:52:37.448121: Epoch time: 118.72 s 
2025-11-29 13:52:38.238915:  
2025-11-29 13:52:38.239003: Epoch 662 
2025-11-29 13:52:38.239133: Current learning rate: 0.00062 
2025-11-29 13:54:37.370901: train_loss -0.8118 
2025-11-29 13:54:37.377073: val_loss -0.8199 
2025-11-29 13:54:37.377187: Pseudo dice [np.float32(0.9574), np.float32(0.8843)] 
2025-11-29 13:54:37.378635: Epoch time: 119.13 s 
2025-11-29 13:54:38.172906:  
2025-11-29 13:54:38.173003: Epoch 663 
2025-11-29 13:54:38.173130: Current learning rate: 0.00057 
2025-11-29 13:56:35.057534: train_loss -0.8118 
2025-11-29 13:56:35.063874: val_loss -0.8134 
2025-11-29 13:56:35.063992: Pseudo dice [np.float32(0.9565), np.float32(0.8839)] 
2025-11-29 13:56:35.065410: Epoch time: 116.89 s 
2025-11-29 13:56:35.819697:  
2025-11-29 13:56:35.819758: Epoch 664 
2025-11-29 13:56:35.819889: Current learning rate: 0.00052 
2025-11-29 13:58:33.506029: train_loss -0.8087 
2025-11-29 13:58:33.512553: val_loss -0.8178 
2025-11-29 13:58:33.512674: Pseudo dice [np.float32(0.9572), np.float32(0.8938)] 
2025-11-29 13:58:33.514085: Epoch time: 117.69 s 
2025-11-29 13:58:33.514220: Yayy! New best EMA pseudo Dice: 0.9169999957084656 
2025-11-29 13:58:35.396623:  
2025-11-29 13:58:35.396770: Epoch 665 
2025-11-29 13:58:35.396824: Current learning rate: 0.00048 
2025-11-29 14:00:37.258871: train_loss -0.8193 
2025-11-29 14:00:37.262176: val_loss -0.8169 
2025-11-29 14:00:37.262402: Pseudo dice [np.float32(0.9588), np.float32(0.8878)] 
2025-11-29 14:00:37.263483: Epoch time: 121.87 s 
2025-11-29 14:00:37.263507: Yayy! New best EMA pseudo Dice: 0.9175999760627747 
2025-11-29 14:00:39.270016:  
2025-11-29 14:00:39.270117: Epoch 666 
2025-11-29 14:00:39.270174: Current learning rate: 0.00043 
2025-11-29 14:02:37.989136: train_loss -0.8109 
2025-11-29 14:02:37.995993: val_loss -0.8123 
2025-11-29 14:02:37.996115: Pseudo dice [np.float32(0.9591), np.float32(0.9122)] 
2025-11-29 14:02:37.997583: Epoch time: 118.72 s 
2025-11-29 14:02:37.997639: Yayy! New best EMA pseudo Dice: 0.9193999767303467 
2025-11-29 14:02:41.410691:  
2025-11-29 14:02:41.410786: Epoch 667 
2025-11-29 14:02:41.410826: Current learning rate: 0.00039 
2025-11-29 14:04:39.256515: train_loss -0.8121 
2025-11-29 14:04:39.262939: val_loss -0.84 
2025-11-29 14:04:39.263054: Pseudo dice [np.float32(0.9537), np.float32(0.8831)] 
2025-11-29 14:04:39.264408: Epoch time: 117.85 s 
2025-11-29 14:04:40.072433:  
2025-11-29 14:04:40.072546: Epoch 668 
2025-11-29 14:04:40.072682: Current learning rate: 0.00035 
2025-11-29 14:06:37.935301: train_loss -0.7951 
2025-11-29 14:06:37.941998: val_loss -0.8346 
2025-11-29 14:06:37.942031: Pseudo dice [np.float32(0.9546), np.float32(0.8918)] 
2025-11-29 14:06:37.943597: Epoch time: 117.87 s 
2025-11-29 14:06:37.943686: Yayy! New best EMA pseudo Dice: 0.919700026512146 
2025-11-29 14:06:41.073677:  
2025-11-29 14:06:41.073839: Epoch 669 
2025-11-29 14:06:41.073878: Current learning rate: 0.00031 
2025-11-29 14:08:39.283784: train_loss -0.8234 
2025-11-29 14:08:39.290399: val_loss -0.8292 
2025-11-29 14:08:39.290435: Pseudo dice [np.float32(0.958), np.float32(0.8895)] 
2025-11-29 14:08:39.291845: Epoch time: 118.21 s 
2025-11-29 14:08:39.291970: Yayy! New best EMA pseudo Dice: 0.9200999736785889 
2025-11-29 14:08:41.349530:  
2025-11-29 14:08:41.349633: Epoch 670 
2025-11-29 14:08:41.349673: Current learning rate: 0.00028 
2025-11-29 14:10:40.264624: train_loss -0.8244 
2025-11-29 14:10:40.270732: val_loss -0.8171 
2025-11-29 14:10:40.270764: Pseudo dice [np.float32(0.957), np.float32(0.8868)] 
2025-11-29 14:10:40.272252: Epoch time: 118.92 s 
2025-11-29 14:10:40.272313: Yayy! New best EMA pseudo Dice: 0.9203000068664551 
2025-11-29 14:10:42.357045:  
2025-11-29 14:10:42.357131: Epoch 671 
2025-11-29 14:10:42.357177: Current learning rate: 0.00025 
2025-11-29 14:12:39.478443: train_loss -0.8193 
2025-11-29 14:12:39.484414: val_loss -0.7734 
2025-11-29 14:12:39.484530: Pseudo dice [np.float32(0.9565), np.float32(0.8739)] 
2025-11-29 14:12:39.486065: Epoch time: 117.12 s 
2025-11-29 14:12:40.316518:  
2025-11-29 14:12:40.316641: Epoch 672 
2025-11-29 14:12:40.316774: Current learning rate: 0.00022 
2025-11-29 14:14:38.637675: train_loss -0.8177 
2025-11-29 14:14:38.644183: val_loss -0.825 
2025-11-29 14:14:38.644218: Pseudo dice [np.float32(0.955), np.float32(0.8842)] 
2025-11-29 14:14:38.645791: Epoch time: 118.32 s 
2025-11-29 14:14:39.485114:  
2025-11-29 14:14:39.485206: Epoch 673 
2025-11-29 14:14:39.485332: Current learning rate: 0.00019 
2025-11-29 14:16:37.884645: train_loss -0.8159 
2025-11-29 14:16:37.890763: val_loss -0.8147 
2025-11-29 14:16:37.890881: Pseudo dice [np.float32(0.9567), np.float32(0.8851)] 
2025-11-29 14:16:37.892381: Epoch time: 118.4 s 
2025-11-29 14:16:42.547815:  
2025-11-29 14:16:42.547879: Epoch 674 
2025-11-29 14:16:42.547918: Current learning rate: 0.00016 
2025-11-29 14:18:40.681972: train_loss -0.8126 
2025-11-29 14:18:40.688401: val_loss -0.8168 
2025-11-29 14:18:40.688525: Pseudo dice [np.float32(0.9536), np.float32(0.8799)] 
2025-11-29 14:18:40.689958: Epoch time: 118.13 s 
2025-11-29 14:18:41.559830:  
2025-11-29 14:18:41.559917: Epoch 675 
2025-11-29 14:18:41.560122: Current learning rate: 0.00013 
2025-11-29 14:20:40.235882: train_loss -0.8048 
2025-11-29 14:20:40.242400: val_loss -0.8392 
2025-11-29 14:20:40.242524: Pseudo dice [np.float32(0.955), np.float32(0.894)] 
2025-11-29 14:20:40.244088: Epoch time: 118.68 s 
2025-11-29 14:20:41.131108:  
2025-11-29 14:20:41.131188: Epoch 676 
2025-11-29 14:20:41.131320: Current learning rate: 0.00011 
2025-11-29 14:22:39.319931: train_loss -0.8196 
2025-11-29 14:22:39.326720: val_loss -0.8275 
2025-11-29 14:22:39.326835: Pseudo dice [np.float32(0.9552), np.float32(0.8799)] 
2025-11-29 14:22:39.328225: Epoch time: 118.19 s 
2025-11-29 14:22:40.186763:  
2025-11-29 14:22:40.186848: Epoch 677 
2025-11-29 14:22:40.187062: Current learning rate: 9e-05 
2025-11-29 14:24:38.691848: train_loss -0.819 
2025-11-29 14:24:38.698264: val_loss -0.8112 
2025-11-29 14:24:38.698380: Pseudo dice [np.float32(0.959), np.float32(0.8902)] 
2025-11-29 14:24:38.699813: Epoch time: 118.51 s 
2025-11-29 14:24:39.543294:  
2025-11-29 14:24:39.543424: Epoch 678 
2025-11-29 14:24:39.543669: Current learning rate: 7e-05 
2025-11-29 14:26:36.433743: train_loss -0.8164 
2025-11-29 14:26:36.439431: val_loss -0.8246 
2025-11-29 14:26:36.439549: Pseudo dice [np.float32(0.9537), np.float32(0.8918)] 
2025-11-29 14:26:36.441045: Epoch time: 116.89 s 
2025-11-29 14:26:36.441154: Yayy! New best EMA pseudo Dice: 0.9204999804496765 
2025-11-29 14:26:39.732492:  
2025-11-29 14:26:39.732587: Epoch 679 
2025-11-29 14:26:39.732728: Current learning rate: 6e-05 
2025-11-29 14:28:37.532139: train_loss -0.8128 
2025-11-29 14:28:37.538210: val_loss -0.8372 
2025-11-29 14:28:37.538247: Pseudo dice [np.float32(0.9595), np.float32(0.8985)] 
2025-11-29 14:28:37.539759: Epoch time: 117.8 s 
2025-11-29 14:28:37.539814: Yayy! New best EMA pseudo Dice: 0.9214000105857849 
2025-11-29 14:28:41.138937:  
2025-11-29 14:28:41.139020: Epoch 680 
2025-11-29 14:28:41.139151: Current learning rate: 4e-05 
2025-11-29 14:30:38.561850: train_loss -0.8051 
2025-11-29 14:30:38.567669: val_loss -0.8287 
2025-11-29 14:30:38.567708: Pseudo dice [np.float32(0.9527), np.float32(0.8787)] 
2025-11-29 14:30:38.569227: Epoch time: 117.43 s 
2025-11-29 14:30:39.401510:  
2025-11-29 14:30:39.401599: Epoch 681 
2025-11-29 14:30:39.401813: Current learning rate: 3e-05 
2025-11-29 14:32:37.692833: train_loss -0.8155 
2025-11-29 14:32:37.698535: val_loss -0.8404 
2025-11-29 14:32:37.698652: Pseudo dice [np.float32(0.9555), np.float32(0.8762)] 
2025-11-29 14:32:37.700056: Epoch time: 118.29 s 
2025-11-29 14:32:38.521245:  
2025-11-29 14:32:38.521381: Epoch 682 
2025-11-29 14:32:38.521596: Current learning rate: 2e-05 
2025-11-29 14:34:36.875766: train_loss -0.8094 
2025-11-29 14:34:36.882231: val_loss -0.8286 
2025-11-29 14:34:36.882263: Pseudo dice [np.float32(0.9576), np.float32(0.8898)] 
2025-11-29 14:34:36.884178: Epoch time: 118.36 s 
2025-11-29 14:34:37.753574:  
2025-11-29 14:34:37.753664: Epoch 683 
2025-11-29 14:34:37.753877: Current learning rate: 1e-05 
2025-11-29 14:36:35.891810: train_loss -0.8196 
2025-11-29 14:36:35.898343: val_loss -0.8387 
2025-11-29 14:36:35.898466: Pseudo dice [np.float32(0.9557), np.float32(0.8804)] 
2025-11-29 14:36:35.899942: Epoch time: 118.14 s 
2025-11-29 14:36:40.620813:  
2025-11-29 14:36:40.620916: Epoch 684 
2025-11-29 14:36:40.621047: Current learning rate: 1e-05 
2025-11-29 14:38:38.391951: train_loss -0.8068 
2025-11-29 14:38:38.398471: val_loss -0.8209 
2025-11-29 14:38:38.398512: Pseudo dice [np.float32(0.9589), np.float32(0.8858)] 
2025-11-29 14:38:38.399926: Epoch time: 117.77 s 
2025-11-29 14:38:39.286390:  
2025-11-29 14:38:39.286470: Epoch 685 
2025-11-29 14:38:39.286598: Current learning rate: 0.0 
2025-11-29 14:40:36.804883: train_loss -0.8218 
2025-11-29 14:40:36.811471: val_loss -0.8214 
2025-11-29 14:40:36.811590: Pseudo dice [np.float32(0.9529), np.float32(0.8909)] 
2025-11-29 14:40:36.813230: Epoch time: 117.52 s 
2025-11-29 14:40:37.673732:  
2025-11-29 14:40:37.673833: Epoch 686 
2025-11-29 14:40:37.673961: Current learning rate: 0.0 
2025-11-29 14:42:35.600344: train_loss -0.8181 
2025-11-29 14:42:35.606105: val_loss -0.8101 
2025-11-29 14:42:35.606222: Pseudo dice [np.float32(0.9559), np.float32(0.8739)] 
2025-11-29 14:42:35.607557: Epoch time: 117.93 s 
2025-11-29 14:42:36.472811:  
2025-11-29 14:42:36.473164: Epoch 687 
2025-11-29 14:42:36.473290: Current learning rate: 0.0 
2025-11-29 14:44:35.287173: train_loss -0.8186 
2025-11-29 14:44:35.293760: val_loss -0.8461 
2025-11-29 14:44:35.293876: Pseudo dice [np.float32(0.9543), np.float32(0.8855)] 
2025-11-29 14:44:35.295348: Epoch time: 118.82 s 
2025-11-29 14:44:36.120541:  
2025-11-29 14:44:36.120640: Epoch 688 
2025-11-29 14:44:36.120771: Current learning rate: 0.0 
2025-11-29 14:46:34.448509: train_loss -0.812 
2025-11-29 14:46:34.455067: val_loss -0.8171 
2025-11-29 14:46:34.455186: Pseudo dice [np.float32(0.9527), np.float32(0.876)] 
2025-11-29 14:46:34.456812: Epoch time: 118.33 s 
2025-11-29 14:46:35.321546:  
2025-11-29 14:46:35.321638: Epoch 689 
2025-11-29 14:46:35.321860: Current learning rate: 1e-05 
2025-11-29 14:48:34.011050: train_loss -0.8175 
2025-11-29 14:48:34.017778: val_loss -0.7707 
2025-11-29 14:48:34.017895: Pseudo dice [np.float32(0.9562), np.float32(0.8873)] 
2025-11-29 14:48:34.019204: Epoch time: 118.69 s 
2025-11-29 14:48:34.900233:  
2025-11-29 14:48:34.900307: Epoch 690 
2025-11-29 14:48:34.900518: Current learning rate: 1e-05 
2025-11-29 14:50:32.307483: train_loss -0.8218 
2025-11-29 14:50:32.314003: val_loss -0.7845 
2025-11-29 14:50:32.314036: Pseudo dice [np.float32(0.9597), np.float32(0.8907)] 
2025-11-29 14:50:32.315424: Epoch time: 117.41 s 
2025-11-29 14:50:33.126336:  
2025-11-29 14:50:33.126473: Epoch 691 
2025-11-29 14:50:33.126703: Current learning rate: 2e-05 
2025-11-29 14:52:31.658304: train_loss -0.8102 
2025-11-29 14:52:31.665214: val_loss -0.8289 
2025-11-29 14:52:31.665329: Pseudo dice [np.float32(0.9562), np.float32(0.9012)] 
2025-11-29 14:52:31.666972: Epoch time: 118.53 s 
2025-11-29 14:52:32.525813:  
2025-11-29 14:52:32.525891: Epoch 692 
2025-11-29 14:52:32.526100: Current learning rate: 3e-05 
2025-11-29 14:54:30.755882: train_loss -0.8155 
2025-11-29 14:54:30.761937: val_loss -0.84 
2025-11-29 14:54:30.762142: Pseudo dice [np.float32(0.9526), np.float32(0.8822)] 
2025-11-29 14:54:30.763643: Epoch time: 118.23 s 
2025-11-29 14:54:31.635183:  
2025-11-29 14:54:31.635286: Epoch 693 
2025-11-29 14:54:31.635499: Current learning rate: 4e-05 
2025-11-29 14:56:29.410336: train_loss -0.82 
2025-11-29 14:56:29.416412: val_loss -0.8247 
2025-11-29 14:56:29.416447: Pseudo dice [np.float32(0.9559), np.float32(0.8726)] 
2025-11-29 14:56:29.417917: Epoch time: 117.78 s 
2025-11-29 14:56:34.206516:  
2025-11-29 14:56:34.206603: Epoch 694 
2025-11-29 14:56:34.206741: Current learning rate: 5e-05 
2025-11-29 14:58:32.673690: train_loss -0.8156 
2025-11-29 14:58:32.680270: val_loss -0.8071 
2025-11-29 14:58:32.680386: Pseudo dice [np.float32(0.9519), np.float32(0.8718)] 
2025-11-29 14:58:32.681767: Epoch time: 118.47 s 
2025-11-29 14:58:33.507531:  
2025-11-29 14:58:33.507634: Epoch 695 
2025-11-29 14:58:33.507871: Current learning rate: 7e-05 
2025-11-29 15:00:31.938938: train_loss -0.8178 
2025-11-29 15:00:31.945675: val_loss -0.83 
2025-11-29 15:00:31.945793: Pseudo dice [np.float32(0.9556), np.float32(0.8901)] 
2025-11-29 15:00:31.947421: Epoch time: 118.43 s 
2025-11-29 15:00:32.845407:  
2025-11-29 15:00:32.845499: Epoch 696 
2025-11-29 15:00:32.845739: Current learning rate: 9e-05 
2025-11-29 15:02:31.395394: train_loss -0.8144 
2025-11-29 15:02:31.401928: val_loss -0.8277 
2025-11-29 15:02:31.402014: Pseudo dice [np.float32(0.9548), np.float32(0.8846)] 
2025-11-29 15:02:31.403378: Epoch time: 118.55 s 
2025-11-29 15:02:32.286133:  
2025-11-29 15:02:32.286217: Epoch 697 
2025-11-29 15:02:32.286353: Current learning rate: 0.0001 
2025-11-29 15:04:30.722212: train_loss -0.8196 
2025-11-29 15:04:30.728812: val_loss -0.8374 
2025-11-29 15:04:30.729026: Pseudo dice [np.float32(0.9602), np.float32(0.8984)] 
2025-11-29 15:04:30.730453: Epoch time: 118.44 s 
2025-11-29 15:04:31.612620:  
2025-11-29 15:04:31.612797: Epoch 698 
2025-11-29 15:04:31.612938: Current learning rate: 0.00013 
2025-11-29 15:06:28.241537: train_loss -0.8109 
2025-11-29 15:06:28.247609: val_loss -0.8546 
2025-11-29 15:06:28.247695: Pseudo dice [np.float32(0.9598), np.float32(0.8982)] 
2025-11-29 15:06:28.249228: Epoch time: 116.63 s 
2025-11-29 15:06:28.249285: Yayy! New best EMA pseudo Dice: 0.9214000105857849 
2025-11-29 15:06:31.333276:  
2025-11-29 15:06:31.333434: Epoch 699 
2025-11-29 15:06:31.333492: Current learning rate: 0.00015 
2025-11-29 15:08:29.473545: train_loss -0.8038 
2025-11-29 15:08:29.480168: val_loss -0.8082 
2025-11-29 15:08:29.480289: Pseudo dice [np.float32(0.9511), np.float32(0.8751)] 
2025-11-29 15:08:29.481727: Epoch time: 118.15 s 
2025-11-29 15:08:31.478498:  
2025-11-29 15:08:31.478631: Epoch 700 
2025-11-29 15:08:31.478738: Current learning rate: 0.00017 
2025-11-29 15:10:29.439580: train_loss -0.816 
2025-11-29 15:10:29.446215: val_loss -0.8279 
2025-11-29 15:10:29.446332: Pseudo dice [np.float32(0.9553), np.float32(0.8896)] 
2025-11-29 15:10:29.447943: Epoch time: 117.96 s 
2025-11-29 15:10:30.285169:  
2025-11-29 15:10:30.285247: Epoch 701 
2025-11-29 15:10:30.285389: Current learning rate: 0.0002 
2025-11-29 15:12:29.229971: train_loss -0.815 
2025-11-29 15:12:29.236932: val_loss -0.8043 
2025-11-29 15:12:29.237049: Pseudo dice [np.float32(0.9562), np.float32(0.8741)] 
2025-11-29 15:12:29.238413: Epoch time: 118.95 s 
2025-11-29 15:12:30.093382:  
2025-11-29 15:12:30.093532: Epoch 702 
2025-11-29 15:12:30.093688: Current learning rate: 0.00022 
2025-11-29 15:14:29.027865: train_loss -0.8236 
2025-11-29 15:14:29.034785: val_loss -0.8013 
2025-11-29 15:14:29.034901: Pseudo dice [np.float32(0.9608), np.float32(0.8926)] 
2025-11-29 15:14:29.036302: Epoch time: 118.94 s 
2025-11-29 15:14:29.851312:  
2025-11-29 15:14:29.851427: Epoch 703 
2025-11-29 15:14:29.851569: Current learning rate: 0.00025 
2025-11-29 15:16:28.036983: train_loss -0.8123 
2025-11-29 15:16:28.043686: val_loss -0.8294 
2025-11-29 15:16:28.043803: Pseudo dice [np.float32(0.9551), np.float32(0.877)] 
2025-11-29 15:16:28.045298: Epoch time: 118.19 s 
2025-11-29 15:16:32.795951:  
2025-11-29 15:16:32.796048: Epoch 704 
2025-11-29 15:16:32.796104: Current learning rate: 0.00028 
2025-11-29 15:18:30.868687: train_loss -0.8134 
2025-11-29 15:18:30.875377: val_loss -0.8037 
2025-11-29 15:18:30.875493: Pseudo dice [np.float32(0.9551), np.float32(0.8692)] 
2025-11-29 15:18:30.876887: Epoch time: 118.07 s 
2025-11-29 15:18:31.729544:  
2025-11-29 15:18:31.729651: Epoch 705 
2025-11-29 15:18:31.729985: Current learning rate: 0.00031 
2025-11-29 15:20:30.083453: train_loss -0.8146 
2025-11-29 15:20:30.089805: val_loss -0.835 
2025-11-29 15:20:30.089920: Pseudo dice [np.float32(0.955), np.float32(0.8864)] 
2025-11-29 15:20:30.091118: Epoch time: 118.36 s 
2025-11-29 15:20:30.956657:  
2025-11-29 15:20:30.956768: Epoch 706 
2025-11-29 15:20:30.956904: Current learning rate: 0.00035 
2025-11-29 15:22:29.155075: train_loss -0.8232 
2025-11-29 15:22:29.160703: val_loss -0.827 
2025-11-29 15:22:29.160820: Pseudo dice [np.float32(0.9562), np.float32(0.8938)] 
2025-11-29 15:22:29.162175: Epoch time: 118.2 s 
2025-11-29 15:22:30.035988:  
2025-11-29 15:22:30.036186: Epoch 707 
2025-11-29 15:22:30.036335: Current learning rate: 0.00038 
2025-11-29 15:24:27.903987: train_loss -0.8094 
2025-11-29 15:24:27.910479: val_loss -0.8144 
2025-11-29 15:24:27.910599: Pseudo dice [np.float32(0.9552), np.float32(0.8833)] 
2025-11-29 15:24:27.912071: Epoch time: 117.87 s 
2025-11-29 15:24:28.791253:  
2025-11-29 15:24:28.791368: Epoch 708 
2025-11-29 15:24:28.791512: Current learning rate: 0.00041 
2025-11-29 15:26:27.064621: train_loss -0.8036 
2025-11-29 15:26:27.071083: val_loss -0.7852 
2025-11-29 15:26:27.071116: Pseudo dice [np.float32(0.9542), np.float32(0.879)] 
2025-11-29 15:26:27.072472: Epoch time: 118.28 s 
2025-11-29 15:26:27.961706:  
2025-11-29 15:26:27.962090: Epoch 709 
2025-11-29 15:26:27.962233: Current learning rate: 0.00045 
2025-11-29 15:28:24.833735: train_loss -0.8258 
2025-11-29 15:28:24.840086: val_loss -0.8595 
2025-11-29 15:28:24.840301: Pseudo dice [np.float32(0.9618), np.float32(0.9041)] 
2025-11-29 15:28:24.841802: Epoch time: 116.87 s 
2025-11-29 15:28:25.718523:  
2025-11-29 15:28:25.718973: Epoch 710 
2025-11-29 15:28:25.719121: Current learning rate: 0.00049 
2025-11-29 15:30:25.595207: train_loss -0.8087 
2025-11-29 15:30:25.601539: val_loss -0.8463 
2025-11-29 15:30:25.601660: Pseudo dice [np.float32(0.9559), np.float32(0.8854)] 
2025-11-29 15:30:25.603202: Epoch time: 119.88 s 
2025-11-29 15:30:26.438257:  
2025-11-29 15:30:26.438407: Epoch 711 
2025-11-29 15:30:26.438548: Current learning rate: 0.00053 
2025-11-29 15:32:24.364669: train_loss -0.8138 
2025-11-29 15:32:24.370569: val_loss -0.8371 
2025-11-29 15:32:24.370694: Pseudo dice [np.float32(0.961), np.float32(0.8964)] 
2025-11-29 15:32:24.372195: Epoch time: 117.93 s 
2025-11-29 15:32:24.372342: Yayy! New best EMA pseudo Dice: 0.9218000173568726 
2025-11-29 15:32:27.862283:  
2025-11-29 15:32:27.862594: Epoch 712 
2025-11-29 15:32:27.862792: Current learning rate: 0.00057 
2025-11-29 15:34:26.300896: train_loss -0.8294 
2025-11-29 15:34:26.307503: val_loss -0.8099 
2025-11-29 15:34:26.307629: Pseudo dice [np.float32(0.9542), np.float32(0.888)] 
2025-11-29 15:34:26.309088: Epoch time: 118.47 s 
2025-11-29 15:34:27.184839:  
2025-11-29 15:34:27.184935: Epoch 713 
2025-11-29 15:34:27.185082: Current learning rate: 0.00061 
2025-11-29 15:36:26.026541: train_loss -0.8057 
2025-11-29 15:36:26.033378: val_loss -0.854 
2025-11-29 15:36:26.033498: Pseudo dice [np.float32(0.9556), np.float32(0.8826)] 
2025-11-29 15:36:26.035067: Epoch time: 118.85 s 
2025-11-29 15:36:26.905375:  
2025-11-29 15:36:26.905474: Epoch 714 
2025-11-29 15:36:26.905633: Current learning rate: 0.00065 
2025-11-29 15:38:30.200908: train_loss -0.8174 
2025-11-29 15:38:30.205553: val_loss -0.8453 
2025-11-29 15:38:30.205583: Pseudo dice [np.float32(0.958), np.float32(0.882)] 
2025-11-29 15:38:30.206910: Epoch time: 123.3 s 
2025-11-29 15:38:30.743599:  
2025-11-29 15:38:30.743735: Epoch 715 
2025-11-29 15:38:30.743794: Current learning rate: 0.0007 
2025-11-29 15:40:28.908099: train_loss -0.817 
2025-11-29 15:40:28.914535: val_loss -0.8443 
2025-11-29 15:40:28.914651: Pseudo dice [np.float32(0.9524), np.float32(0.8822)] 
2025-11-29 15:40:28.916034: Epoch time: 118.17 s 
2025-11-29 15:40:29.770510:  
2025-11-29 15:40:29.770600: Epoch 716 
2025-11-29 15:40:29.770749: Current learning rate: 0.00074 
2025-11-29 15:42:28.165343: train_loss -0.8156 
2025-11-29 15:42:28.171755: val_loss -0.8282 
2025-11-29 15:42:28.171874: Pseudo dice [np.float32(0.9598), np.float32(0.8913)] 
2025-11-29 15:42:28.173382: Epoch time: 118.4 s 
2025-11-29 15:42:29.070352:  
2025-11-29 15:42:29.070484: Epoch 717 
2025-11-29 15:42:29.070629: Current learning rate: 0.00079 
2025-11-29 15:44:27.974109: train_loss -0.8181 
2025-11-29 15:44:27.980888: val_loss -0.8273 
2025-11-29 15:44:27.981005: Pseudo dice [np.float32(0.9571), np.float32(0.8988)] 
2025-11-29 15:44:27.982488: Epoch time: 118.91 s 
2025-11-29 15:44:27.982574: Yayy! New best EMA pseudo Dice: 0.921999990940094 
2025-11-29 15:44:30.123748:  
2025-11-29 15:44:30.123846: Epoch 718 
2025-11-29 15:44:30.123896: Current learning rate: 0.00084 
2025-11-29 15:46:26.908395: train_loss -0.809 
2025-11-29 15:46:26.913896: val_loss -0.7978 
2025-11-29 15:46:26.913929: Pseudo dice [np.float32(0.9537), np.float32(0.881)] 
2025-11-29 15:46:26.915335: Epoch time: 116.79 s 
2025-11-29 15:46:27.653821:  
2025-11-29 15:46:27.653916: Epoch 719 
2025-11-29 15:46:27.654054: Current learning rate: 0.00088 
2025-11-29 15:48:24.894298: train_loss -0.8255 
2025-11-29 15:48:24.900746: val_loss -0.8091 
2025-11-29 15:48:24.900781: Pseudo dice [np.float32(0.9532), np.float32(0.8798)] 
2025-11-29 15:48:24.902414: Epoch time: 117.24 s 
2025-11-29 15:48:25.736744:  
2025-11-29 15:48:25.736855: Epoch 720 
2025-11-29 15:48:25.736999: Current learning rate: 0.00093 
2025-11-29 15:50:23.902292: train_loss -0.8193 
2025-11-29 15:50:23.908920: val_loss -0.7877 
2025-11-29 15:50:23.909036: Pseudo dice [np.float32(0.9531), np.float32(0.884)] 
2025-11-29 15:50:23.910542: Epoch time: 118.17 s 
2025-11-29 15:50:24.803357:  
2025-11-29 15:50:24.803482: Epoch 721 
2025-11-29 15:50:24.803631: Current learning rate: 0.00098 
2025-11-29 15:52:22.400372: train_loss -0.8218 
2025-11-29 15:52:22.406859: val_loss -0.8219 
2025-11-29 15:52:22.406891: Pseudo dice [np.float32(0.9526), np.float32(0.8885)] 
2025-11-29 15:52:22.408553: Epoch time: 117.6 s 
2025-11-29 15:52:23.223523:  
2025-11-29 15:52:23.223628: Epoch 722 
2025-11-29 15:52:23.223773: Current learning rate: 0.00103 
2025-11-29 15:54:20.788970: train_loss -0.8048 
2025-11-29 15:54:20.794874: val_loss -0.8451 
2025-11-29 15:54:20.794990: Pseudo dice [np.float32(0.952), np.float32(0.8707)] 
2025-11-29 15:54:20.796572: Epoch time: 117.57 s 
2025-11-29 15:54:21.660557:  
2025-11-29 15:54:21.660668: Epoch 723 
2025-11-29 15:54:21.660814: Current learning rate: 0.00108 
2025-11-29 15:56:20.933682: train_loss -0.8185 
2025-11-29 15:56:20.939921: val_loss -0.8286 
2025-11-29 15:56:20.939952: Pseudo dice [np.float32(0.9534), np.float32(0.8925)] 
2025-11-29 15:56:20.941364: Epoch time: 119.28 s 
2025-11-29 15:56:21.768651:  
2025-11-29 15:56:21.768727: Epoch 724 
2025-11-29 15:56:21.768870: Current learning rate: 0.00113 
2025-11-29 15:58:24.388709: train_loss -0.8087 
2025-11-29 15:58:24.390191: val_loss -0.8268 
2025-11-29 15:58:24.390223: Pseudo dice [np.float32(0.9531), np.float32(0.8798)] 
2025-11-29 15:58:24.391281: Epoch time: 122.62 s 
2025-11-29 15:58:24.940219:  
2025-11-29 15:58:24.940295: Epoch 725 
2025-11-29 15:58:24.940406: Current learning rate: 0.00119 
2025-11-29 16:00:23.157164: train_loss -0.8239 
2025-11-29 16:00:23.163835: val_loss -0.8432 
2025-11-29 16:00:23.163873: Pseudo dice [np.float32(0.9577), np.float32(0.8936)] 
2025-11-29 16:00:23.165498: Epoch time: 118.22 s 
2025-11-29 16:00:24.049286:  
2025-11-29 16:00:24.049381: Epoch 726 
2025-11-29 16:00:24.049524: Current learning rate: 0.00124 
2025-11-29 16:02:21.874042: train_loss -0.8082 
2025-11-29 16:02:21.880411: val_loss -0.8298 
2025-11-29 16:02:21.880528: Pseudo dice [np.float32(0.955), np.float32(0.8924)] 
2025-11-29 16:02:21.882084: Epoch time: 117.83 s 
2025-11-29 16:02:22.741906:  
2025-11-29 16:02:22.741991: Epoch 727 
2025-11-29 16:02:22.742151: Current learning rate: 0.00129 
2025-11-29 16:04:19.700252: train_loss -0.8086 
2025-11-29 16:04:19.706982: val_loss -0.8257 
2025-11-29 16:04:19.707014: Pseudo dice [np.float32(0.9568), np.float32(0.876)] 
2025-11-29 16:04:19.708474: Epoch time: 116.96 s 
2025-11-29 16:04:20.545989:  
2025-11-29 16:04:20.546120: Epoch 728 
2025-11-29 16:04:20.546274: Current learning rate: 0.00135 
2025-11-29 16:06:18.612305: train_loss -0.8008 
2025-11-29 16:06:18.618984: val_loss -0.8283 
2025-11-29 16:06:18.619187: Pseudo dice [np.float32(0.9591), np.float32(0.8735)] 
2025-11-29 16:06:18.620722: Epoch time: 118.07 s 
2025-11-29 16:06:19.475372:  
2025-11-29 16:06:19.475510: Epoch 729 
2025-11-29 16:06:19.475656: Current learning rate: 0.0014 
2025-11-29 16:08:17.899257: train_loss -0.8131 
2025-11-29 16:08:17.905758: val_loss -0.8426 
2025-11-29 16:08:17.905793: Pseudo dice [np.float32(0.954), np.float32(0.8736)] 
2025-11-29 16:08:17.907192: Epoch time: 118.43 s 
2025-11-29 16:08:18.793832:  
2025-11-29 16:08:18.794019: Epoch 730 
2025-11-29 16:08:18.794164: Current learning rate: 0.00145 
2025-11-29 16:10:17.238922: train_loss -0.8235 
2025-11-29 16:10:17.245201: val_loss -0.8229 
2025-11-29 16:10:17.245334: Pseudo dice [np.float32(0.9554), np.float32(0.8812)] 
2025-11-29 16:10:17.246821: Epoch time: 118.45 s 
2025-11-29 16:10:19.017646:  
2025-11-29 16:10:19.017751: Epoch 731 
2025-11-29 16:10:19.017808: Current learning rate: 0.00151 
2025-11-29 16:12:16.657905: train_loss -0.8088 
2025-11-29 16:12:16.665036: val_loss -0.841 
2025-11-29 16:12:16.665166: Pseudo dice [np.float32(0.9576), np.float32(0.8952)] 
2025-11-29 16:12:16.666736: Epoch time: 117.64 s 
2025-11-29 16:12:17.534388:  
2025-11-29 16:12:17.534465: Epoch 732 
2025-11-29 16:12:17.534609: Current learning rate: 0.00156 
2025-11-29 16:14:15.567608: train_loss -0.8211 
2025-11-29 16:14:15.574110: val_loss -0.8196 
2025-11-29 16:14:15.574142: Pseudo dice [np.float32(0.9528), np.float32(0.8825)] 
2025-11-29 16:14:15.575448: Epoch time: 118.04 s 
2025-11-29 16:14:16.412444:  
2025-11-29 16:14:16.412539: Epoch 733 
2025-11-29 16:14:16.412709: Current learning rate: 0.00162 
2025-11-29 16:16:14.758944: train_loss -0.7812 
2025-11-29 16:16:14.765804: val_loss -0.8137 
2025-11-29 16:16:14.765932: Pseudo dice [np.float32(0.9555), np.float32(0.8785)] 
2025-11-29 16:16:14.767285: Epoch time: 118.35 s 
2025-11-29 16:16:15.604850:  
2025-11-29 16:16:15.604942: Epoch 734 
2025-11-29 16:16:15.605097: Current learning rate: 0.00167 
2025-11-29 16:18:14.596767: train_loss -0.8129 
2025-11-29 16:18:14.603231: val_loss -0.8178 
2025-11-29 16:18:14.603345: Pseudo dice [np.float32(0.9524), np.float32(0.8849)] 
2025-11-29 16:18:14.604872: Epoch time: 119.0 s 
2025-11-29 16:18:19.501897:  
2025-11-29 16:18:19.501999: Epoch 735 
2025-11-29 16:18:19.502063: Current learning rate: 0.00173 
2025-11-29 16:20:17.451885: train_loss -0.8073 
2025-11-29 16:20:17.457922: val_loss -0.8273 
2025-11-29 16:20:17.458041: Pseudo dice [np.float32(0.9533), np.float32(0.8715)] 
2025-11-29 16:20:17.459298: Epoch time: 117.95 s 
2025-11-29 16:20:18.298352:  
2025-11-29 16:20:18.298476: Epoch 736 
2025-11-29 16:20:18.298620: Current learning rate: 0.00179 
2025-11-29 16:22:17.094382: train_loss -0.8117 
2025-11-29 16:22:17.100820: val_loss -0.8145 
2025-11-29 16:22:17.100945: Pseudo dice [np.float32(0.9504), np.float32(0.8821)] 
2025-11-29 16:22:17.102606: Epoch time: 118.8 s 
2025-11-29 16:22:18.029512:  
2025-11-29 16:22:18.029689: Epoch 737 
2025-11-29 16:22:18.029840: Current learning rate: 0.00184 
2025-11-29 16:24:16.460973: train_loss -0.8039 
2025-11-29 16:24:16.467223: val_loss -0.8295 
2025-11-29 16:24:16.467337: Pseudo dice [np.float32(0.9589), np.float32(0.8846)] 
2025-11-29 16:24:16.468961: Epoch time: 118.43 s 
2025-11-29 16:24:17.340653:  
2025-11-29 16:24:17.340776: Epoch 738 
2025-11-29 16:24:17.340921: Current learning rate: 0.0019 
2025-11-29 16:26:15.561006: train_loss -0.8154 
2025-11-29 16:26:15.567380: val_loss -0.8297 
2025-11-29 16:26:15.567498: Pseudo dice [np.float32(0.9609), np.float32(0.8966)] 
2025-11-29 16:26:15.568997: Epoch time: 118.22 s 
2025-11-29 16:26:16.490707:  
2025-11-29 16:26:16.490798: Epoch 739 
2025-11-29 16:26:16.490949: Current learning rate: 0.00195 
2025-11-29 16:28:14.949045: train_loss -0.8 
2025-11-29 16:28:14.955968: val_loss -0.8191 
2025-11-29 16:28:14.956094: Pseudo dice [np.float32(0.9536), np.float32(0.8787)] 
2025-11-29 16:28:14.957645: Epoch time: 118.46 s 
2025-11-29 16:28:15.834646:  
2025-11-29 16:28:15.834899: Epoch 740 
2025-11-29 16:28:15.835054: Current learning rate: 0.00201 
2025-11-29 16:30:14.560484: train_loss -0.8195 
2025-11-29 16:30:14.567144: val_loss -0.8101 
2025-11-29 16:30:14.567258: Pseudo dice [np.float32(0.9549), np.float32(0.8745)] 
2025-11-29 16:30:14.568682: Epoch time: 118.73 s 
2025-11-29 16:30:15.467774:  
2025-11-29 16:30:15.467872: Epoch 741 
2025-11-29 16:30:15.468017: Current learning rate: 0.00206 
2025-11-29 16:32:13.179948: train_loss -0.8281 
2025-11-29 16:32:13.186009: val_loss -0.8181 
2025-11-29 16:32:13.186042: Pseudo dice [np.float32(0.9489), np.float32(0.8824)] 
2025-11-29 16:32:13.187500: Epoch time: 117.72 s 
2025-11-29 16:32:14.074386:  
2025-11-29 16:32:14.074500: Epoch 742 
2025-11-29 16:32:14.074669: Current learning rate: 0.00212 
2025-11-29 16:34:12.145365: train_loss -0.8148 
2025-11-29 16:34:12.151681: val_loss -0.8169 
2025-11-29 16:34:12.151802: Pseudo dice [np.float32(0.9558), np.float32(0.8894)] 
2025-11-29 16:34:12.153186: Epoch time: 118.07 s 
2025-11-29 16:34:13.014869:  
2025-11-29 16:34:13.014971: Epoch 743 
2025-11-29 16:34:13.015204: Current learning rate: 0.00218 
2025-11-29 16:36:11.663588: train_loss -0.8076 
2025-11-29 16:36:11.670474: val_loss -0.7936 
2025-11-29 16:36:11.670515: Pseudo dice [np.float32(0.9556), np.float32(0.8753)] 
2025-11-29 16:36:11.672095: Epoch time: 118.65 s 
2025-11-29 16:36:12.563313:  
2025-11-29 16:36:12.563422: Epoch 744 
2025-11-29 16:36:12.563569: Current learning rate: 0.00223 
2025-11-29 16:38:11.227353: train_loss -0.7993 
2025-11-29 16:38:11.233538: val_loss -0.8296 
2025-11-29 16:38:11.233573: Pseudo dice [np.float32(0.956), np.float32(0.8825)] 
2025-11-29 16:38:11.235238: Epoch time: 118.67 s 
2025-11-29 16:38:12.088244:  
2025-11-29 16:38:12.088336: Epoch 745 
2025-11-29 16:38:12.088475: Current learning rate: 0.00229 
2025-11-29 16:40:10.996904: train_loss -0.8147 
2025-11-29 16:40:11.002993: val_loss -0.7926 
2025-11-29 16:40:11.003296: Pseudo dice [np.float32(0.9553), np.float32(0.8896)] 
2025-11-29 16:40:11.004863: Epoch time: 118.91 s 
2025-11-29 16:40:15.875522:  
2025-11-29 16:40:15.875687: Epoch 746 
2025-11-29 16:40:15.875741: Current learning rate: 0.00234 
2025-11-29 16:42:14.110142: train_loss -0.8104 
2025-11-29 16:42:14.116592: val_loss -0.8326 
2025-11-29 16:42:14.116707: Pseudo dice [np.float32(0.9538), np.float32(0.8834)] 
2025-11-29 16:42:14.117859: Epoch time: 118.23 s 
2025-11-29 16:42:15.018206:  
2025-11-29 16:42:15.018320: Epoch 747 
2025-11-29 16:42:15.018496: Current learning rate: 0.00239 
2025-11-29 16:44:13.783860: train_loss -0.8113 
2025-11-29 16:44:13.790538: val_loss -0.8303 
2025-11-29 16:44:13.790653: Pseudo dice [np.float32(0.9536), np.float32(0.8848)] 
2025-11-29 16:44:13.792223: Epoch time: 118.77 s 
2025-11-29 16:44:14.680793:  
2025-11-29 16:44:14.680901: Epoch 748 
2025-11-29 16:44:14.681055: Current learning rate: 0.00245 
2025-11-29 16:46:13.207270: train_loss -0.8055 
2025-11-29 16:46:13.213502: val_loss -0.8017 
2025-11-29 16:46:13.213621: Pseudo dice [np.float32(0.9569), np.float32(0.8789)] 
2025-11-29 16:46:13.215100: Epoch time: 118.53 s 
2025-11-29 16:46:14.081249:  
2025-11-29 16:46:14.081399: Epoch 749 
2025-11-29 16:46:14.081539: Current learning rate: 0.0025 
2025-11-29 16:48:13.557776: train_loss -0.8089 
2025-11-29 16:48:13.563732: val_loss -0.8334 
2025-11-29 16:48:13.563849: Pseudo dice [np.float32(0.9552), np.float32(0.8926)] 
2025-11-29 16:48:13.565188: Epoch time: 119.48 s 
2025-11-29 16:48:15.685045:  
2025-11-29 16:48:15.685179: Epoch 750 
2025-11-29 16:48:15.685232: Current learning rate: 0.00255 
2025-11-29 16:50:12.671135: train_loss -0.8047 
2025-11-29 16:50:12.677411: val_loss -0.8064 
2025-11-29 16:50:12.677528: Pseudo dice [np.float32(0.9561), np.float32(0.8843)] 
2025-11-29 16:50:12.678851: Epoch time: 116.99 s 
2025-11-29 16:50:13.662361:  
2025-11-29 16:50:13.662919: Epoch 751 
2025-11-29 16:50:13.663062: Current learning rate: 0.0026 
2025-11-29 16:52:13.886474: train_loss -0.801 
2025-11-29 16:52:13.891817: val_loss -0.8514 
2025-11-29 16:52:13.891961: Pseudo dice [np.float32(0.955), np.float32(0.8968)] 
2025-11-29 16:52:13.893228: Epoch time: 120.23 s 
2025-11-29 16:52:14.727268:  
2025-11-29 16:52:14.727379: Epoch 752 
2025-11-29 16:52:14.727529: Current learning rate: 0.00266 
2025-11-29 16:54:13.040337: train_loss -0.8117 
2025-11-29 16:54:13.046682: val_loss -0.8215 
2025-11-29 16:54:13.046772: Pseudo dice [np.float32(0.9545), np.float32(0.8754)] 
2025-11-29 16:54:13.048293: Epoch time: 118.32 s 
2025-11-29 16:54:13.927044:  
2025-11-29 16:54:13.927150: Epoch 753 
2025-11-29 16:54:13.927295: Current learning rate: 0.00271 
2025-11-29 16:56:13.614763: train_loss -0.8063 
2025-11-29 16:56:13.621070: val_loss -0.8203 
2025-11-29 16:56:13.621273: Pseudo dice [np.float32(0.9565), np.float32(0.8895)] 
2025-11-29 16:56:13.622577: Epoch time: 119.69 s 
2025-11-29 16:56:14.478280:  
2025-11-29 16:56:14.478387: Epoch 754 
2025-11-29 16:56:14.478539: Current learning rate: 0.00276 
2025-11-29 16:58:13.464950: train_loss -0.8024 
2025-11-29 16:58:13.471709: val_loss -0.8069 
2025-11-29 16:58:13.471758: Pseudo dice [np.float32(0.955), np.float32(0.869)] 
2025-11-29 16:58:13.473433: Epoch time: 118.99 s 
2025-11-29 16:58:14.321535:  
2025-11-29 16:58:14.321635: Epoch 755 
2025-11-29 16:58:14.321776: Current learning rate: 0.00281 
2025-11-29 17:00:12.404827: train_loss -0.8179 
2025-11-29 17:00:12.412128: val_loss -0.8238 
2025-11-29 17:00:12.412169: Pseudo dice [np.float32(0.9539), np.float32(0.8752)] 
2025-11-29 17:00:12.413731: Epoch time: 118.09 s 
2025-11-29 17:00:13.320056:  
2025-11-29 17:00:13.320153: Epoch 756 
2025-11-29 17:00:13.320302: Current learning rate: 0.00286 
2025-11-29 17:02:13.915511: train_loss -0.8049 
2025-11-29 17:02:13.916706: val_loss -0.7946 
2025-11-29 17:02:13.916735: Pseudo dice [np.float32(0.9583), np.float32(0.8825)] 
2025-11-29 17:02:13.917845: Epoch time: 120.6 s 
2025-11-29 17:02:14.456177:  
2025-11-29 17:02:14.456272: Epoch 757 
2025-11-29 17:02:14.456327: Current learning rate: 0.0029 
2025-11-29 17:04:12.470798: train_loss -0.8171 
2025-11-29 17:04:12.477696: val_loss -0.813 
2025-11-29 17:04:12.477731: Pseudo dice [np.float32(0.9528), np.float32(0.884)] 
2025-11-29 17:04:12.479295: Epoch time: 118.01 s 
2025-11-29 17:04:13.385531:  
2025-11-29 17:04:13.385633: Epoch 758 
2025-11-29 17:04:13.385783: Current learning rate: 0.00295 
2025-11-29 17:06:12.184091: train_loss -0.8197 
2025-11-29 17:06:12.190850: val_loss -0.8161 
2025-11-29 17:06:12.190968: Pseudo dice [np.float32(0.9528), np.float32(0.8712)] 
2025-11-29 17:06:12.192395: Epoch time: 118.8 s 
2025-11-29 17:06:13.059884:  
2025-11-29 17:06:13.059997: Epoch 759 
2025-11-29 17:06:13.060143: Current learning rate: 0.003 
2025-11-29 17:08:11.059836: train_loss -0.8077 
2025-11-29 17:08:11.066041: val_loss -0.8019 
2025-11-29 17:08:11.066156: Pseudo dice [np.float32(0.9547), np.float32(0.8861)] 
2025-11-29 17:08:11.067650: Epoch time: 118.0 s 
2025-11-29 17:08:11.977207:  
2025-11-29 17:08:11.977306: Epoch 760 
2025-11-29 17:08:11.977456: Current learning rate: 0.00304 
2025-11-29 17:10:10.230067: train_loss -0.8214 
2025-11-29 17:10:10.236234: val_loss -0.8045 
2025-11-29 17:10:10.236438: Pseudo dice [np.float32(0.9513), np.float32(0.8729)] 
2025-11-29 17:10:10.238056: Epoch time: 118.26 s 
2025-11-29 17:10:11.100299:  
2025-11-29 17:10:11.100369: Epoch 761 
2025-11-29 17:10:11.100518: Current learning rate: 0.00309 
2025-11-29 17:12:08.752804: train_loss -0.8169 
2025-11-29 17:12:08.759080: val_loss -0.8412 
2025-11-29 17:12:08.759113: Pseudo dice [np.float32(0.9583), np.float32(0.8893)] 
2025-11-29 17:12:08.760660: Epoch time: 117.66 s 
2025-11-29 17:12:09.636769:  
2025-11-29 17:12:09.636887: Epoch 762 
2025-11-29 17:12:09.637026: Current learning rate: 0.00313 
2025-11-29 17:14:08.789279: train_loss -0.8167 
2025-11-29 17:14:08.795789: val_loss -0.813 
2025-11-29 17:14:08.795904: Pseudo dice [np.float32(0.9511), np.float32(0.8676)] 
2025-11-29 17:14:08.797285: Epoch time: 119.16 s 
2025-11-29 17:14:09.673359:  
2025-11-29 17:14:09.673474: Epoch 763 
2025-11-29 17:14:09.673642: Current learning rate: 0.00317 
2025-11-29 17:16:08.472850: train_loss -0.8208 
2025-11-29 17:16:08.479187: val_loss -0.7993 
2025-11-29 17:16:08.479313: Pseudo dice [np.float32(0.9549), np.float32(0.8778)] 
2025-11-29 17:16:08.480706: Epoch time: 118.8 s 
2025-11-29 17:16:09.384976:  
2025-11-29 17:16:09.385226: Epoch 764 
2025-11-29 17:16:09.385378: Current learning rate: 0.00322 
2025-11-29 17:18:07.567560: train_loss -0.8131 
2025-11-29 17:18:07.574119: val_loss -0.8032 
2025-11-29 17:18:07.574233: Pseudo dice [np.float32(0.9532), np.float32(0.8827)] 
2025-11-29 17:18:07.575559: Epoch time: 118.19 s 
2025-11-29 17:18:08.459506:  
2025-11-29 17:18:08.459951: Epoch 765 
2025-11-29 17:18:08.460096: Current learning rate: 0.00326 
2025-11-29 17:20:07.119687: train_loss -0.7949 
2025-11-29 17:20:07.126542: val_loss -0.8175 
2025-11-29 17:20:07.126668: Pseudo dice [np.float32(0.9533), np.float32(0.8858)] 
2025-11-29 17:20:07.128265: Epoch time: 118.66 s 
2025-11-29 17:20:08.017603:  
2025-11-29 17:20:08.017701: Epoch 766 
2025-11-29 17:20:08.017843: Current learning rate: 0.0033 
2025-11-29 17:22:06.719743: train_loss -0.803 
2025-11-29 17:22:06.726434: val_loss -0.7931 
2025-11-29 17:22:06.726465: Pseudo dice [np.float32(0.9534), np.float32(0.872)] 
2025-11-29 17:22:06.727855: Epoch time: 118.71 s 
2025-11-29 17:22:11.527368:  
2025-11-29 17:22:11.527441: Epoch 767 
2025-11-29 17:22:11.527500: Current learning rate: 0.00333 
2025-11-29 17:24:09.718028: train_loss -0.7924 
2025-11-29 17:24:09.724873: val_loss -0.8205 
2025-11-29 17:24:09.725077: Pseudo dice [np.float32(0.9481), np.float32(0.8752)] 
2025-11-29 17:24:09.726426: Epoch time: 118.19 s 
2025-11-29 17:24:10.602122:  
2025-11-29 17:24:10.602217: Epoch 768 
2025-11-29 17:24:10.602371: Current learning rate: 0.00337 
2025-11-29 17:26:08.841388: train_loss -0.8076 
2025-11-29 17:26:08.848102: val_loss -0.8128 
2025-11-29 17:26:08.848313: Pseudo dice [np.float32(0.9519), np.float32(0.8768)] 
2025-11-29 17:26:08.849872: Epoch time: 118.24 s 
2025-11-29 17:26:09.739591:  
2025-11-29 17:26:09.739697: Epoch 769 
2025-11-29 17:26:09.739845: Current learning rate: 0.00341 
2025-11-29 17:28:08.781738: train_loss -0.7995 
2025-11-29 17:28:08.788413: val_loss -0.8066 
2025-11-29 17:28:08.788528: Pseudo dice [np.float32(0.9482), np.float32(0.8659)] 
2025-11-29 17:28:08.789945: Epoch time: 119.05 s 
2025-11-29 17:28:09.669646:  
2025-11-29 17:28:09.669935: Epoch 770 
2025-11-29 17:28:09.670170: Current learning rate: 0.00344 
2025-11-29 17:30:07.937560: train_loss -0.8053 
2025-11-29 17:30:07.944027: val_loss -0.8238 
2025-11-29 17:30:07.944142: Pseudo dice [np.float32(0.9538), np.float32(0.8838)] 
2025-11-29 17:30:07.945622: Epoch time: 118.27 s 
2025-11-29 17:30:08.835064:  
2025-11-29 17:30:08.835285: Epoch 771 
2025-11-29 17:30:08.835429: Current learning rate: 0.00348 
2025-11-29 17:32:07.103928: train_loss -0.8099 
2025-11-29 17:32:07.110590: val_loss -0.808 
2025-11-29 17:32:07.110708: Pseudo dice [np.float32(0.9519), np.float32(0.8646)] 
2025-11-29 17:32:07.112236: Epoch time: 118.27 s 
2025-11-29 17:32:08.000173:  
2025-11-29 17:32:08.000295: Epoch 772 
2025-11-29 17:32:08.000444: Current learning rate: 0.00351 
2025-11-29 17:34:06.156382: train_loss -0.8107 
2025-11-29 17:34:06.162602: val_loss -0.8234 
2025-11-29 17:34:06.162635: Pseudo dice [np.float32(0.9519), np.float32(0.8824)] 
2025-11-29 17:34:06.164140: Epoch time: 118.16 s 
2025-11-29 17:34:07.007879:  
2025-11-29 17:34:07.007995: Epoch 773 
2025-11-29 17:34:07.008138: Current learning rate: 0.00354 
2025-11-29 17:36:05.750975: train_loss -0.7988 
2025-11-29 17:36:05.757896: val_loss -0.8078 
2025-11-29 17:36:05.758102: Pseudo dice [np.float32(0.9473), np.float32(0.8601)] 
2025-11-29 17:36:05.759680: Epoch time: 118.75 s 
2025-11-29 17:36:06.669587:  
2025-11-29 17:36:06.669715: Epoch 774 
2025-11-29 17:36:06.669866: Current learning rate: 0.00357 
2025-11-29 17:38:03.704303: train_loss -0.8122 
2025-11-29 17:38:03.710840: val_loss -0.8251 
2025-11-29 17:38:03.710960: Pseudo dice [np.float32(0.9561), np.float32(0.8788)] 
2025-11-29 17:38:03.712379: Epoch time: 117.04 s 
2025-11-29 17:38:04.582711:  
2025-11-29 17:38:04.582827: Epoch 775 
2025-11-29 17:38:04.582966: Current learning rate: 0.0036 
2025-11-29 17:40:02.773041: train_loss -0.8192 
2025-11-29 17:40:02.779539: val_loss -0.8031 
2025-11-29 17:40:02.779657: Pseudo dice [np.float32(0.9594), np.float32(0.868)] 
2025-11-29 17:40:02.781094: Epoch time: 118.19 s 
2025-11-29 17:40:03.661870:  
2025-11-29 17:40:03.661967: Epoch 776 
2025-11-29 17:40:03.662107: Current learning rate: 0.00363 
2025-11-29 17:42:02.082928: train_loss -0.8014 
2025-11-29 17:42:02.089317: val_loss -0.7989 
2025-11-29 17:42:02.089434: Pseudo dice [np.float32(0.9507), np.float32(0.883)] 
2025-11-29 17:42:02.091014: Epoch time: 118.42 s 
2025-11-29 17:42:02.957935:  
2025-11-29 17:42:02.958029: Epoch 777 
2025-11-29 17:42:02.958171: Current learning rate: 0.00366 
2025-11-29 17:44:04.580176: train_loss -0.8093 
2025-11-29 17:44:04.587327: val_loss -0.7927 
2025-11-29 17:44:04.587455: Pseudo dice [np.float32(0.9541), np.float32(0.876)] 
2025-11-29 17:44:04.589036: Epoch time: 121.63 s 
2025-11-29 17:44:05.473022:  
2025-11-29 17:44:05.473099: Epoch 778 
2025-11-29 17:44:05.473241: Current learning rate: 0.00368 
2025-11-29 17:46:04.549117: train_loss -0.8067 
2025-11-29 17:46:04.555831: val_loss -0.7936 
2025-11-29 17:46:04.555955: Pseudo dice [np.float32(0.9475), np.float32(0.8701)] 
2025-11-29 17:46:04.557491: Epoch time: 119.08 s 
2025-11-29 17:46:05.453417:  
2025-11-29 17:46:05.453545: Epoch 779 
2025-11-29 17:46:05.453692: Current learning rate: 0.00371 
2025-11-29 17:48:03.783890: train_loss -0.7961 
2025-11-29 17:48:03.790498: val_loss -0.8313 
2025-11-29 17:48:03.790532: Pseudo dice [np.float32(0.9496), np.float32(0.877)] 
2025-11-29 17:48:03.792077: Epoch time: 118.33 s 
2025-11-29 17:48:04.712203:  
2025-11-29 17:48:04.712314: Epoch 780 
2025-11-29 17:48:04.712461: Current learning rate: 0.00373 
2025-11-29 17:50:03.440835: train_loss -0.8048 
2025-11-29 17:50:03.446971: val_loss -0.8336 
2025-11-29 17:50:03.447086: Pseudo dice [np.float32(0.9524), np.float32(0.8984)] 
2025-11-29 17:50:03.448652: Epoch time: 118.73 s 
2025-11-29 17:50:04.346701:  
2025-11-29 17:50:04.346816: Epoch 781 
2025-11-29 17:50:04.346963: Current learning rate: 0.00375 
2025-11-29 17:52:03.044172: train_loss -0.8054 
2025-11-29 17:52:03.050894: val_loss -0.8185 
2025-11-29 17:52:03.051009: Pseudo dice [np.float32(0.9491), np.float32(0.876)] 
2025-11-29 17:52:03.052514: Epoch time: 118.7 s 
2025-11-29 17:52:03.922640:  
2025-11-29 17:52:03.922739: Epoch 782 
2025-11-29 17:52:03.922877: Current learning rate: 0.00377 
2025-11-29 17:54:02.327538: train_loss -0.8169 
2025-11-29 17:54:02.334150: val_loss -0.787 
2025-11-29 17:54:02.334183: Pseudo dice [np.float32(0.9482), np.float32(0.8647)] 
2025-11-29 17:54:02.335648: Epoch time: 118.41 s 
2025-11-29 17:54:03.200737:  
2025-11-29 17:54:03.200824: Epoch 783 
2025-11-29 17:54:03.200972: Current learning rate: 0.00379 
2025-11-29 17:56:02.148417: train_loss -0.7935 
2025-11-29 17:56:02.155097: val_loss -0.8176 
2025-11-29 17:56:02.155129: Pseudo dice [np.float32(0.9457), np.float32(0.8724)] 
2025-11-29 17:56:02.156438: Epoch time: 118.95 s 
2025-11-29 17:56:03.001323:  
2025-11-29 17:56:03.001407: Epoch 784 
2025-11-29 17:56:03.001551: Current learning rate: 0.00381 
2025-11-29 17:58:01.544197: train_loss -0.7954 
2025-11-29 17:58:01.550462: val_loss -0.8034 
2025-11-29 17:58:01.550609: Pseudo dice [np.float32(0.9455), np.float32(0.8692)] 
2025-11-29 17:58:01.552138: Epoch time: 118.55 s 
2025-11-29 17:58:02.414829:  
2025-11-29 17:58:02.414923: Epoch 785 
2025-11-29 17:58:02.415067: Current learning rate: 0.00382 
2025-11-29 18:00:01.909214: train_loss -0.7955 
2025-11-29 18:00:01.915270: val_loss -0.818 
2025-11-29 18:00:01.915563: Pseudo dice [np.float32(0.9497), np.float32(0.8822)] 
2025-11-29 18:00:01.917137: Epoch time: 119.5 s 
2025-11-29 18:00:02.817807:  
2025-11-29 18:00:02.817917: Epoch 786 
2025-11-29 18:00:02.818067: Current learning rate: 0.00384 
2025-11-29 18:01:59.784135: train_loss -0.8026 
2025-11-29 18:01:59.790441: val_loss -0.7934 
2025-11-29 18:01:59.790507: Pseudo dice [np.float32(0.9518), np.float32(0.8626)] 
2025-11-29 18:01:59.791993: Epoch time: 116.97 s 
2025-11-29 18:02:00.645141:  
2025-11-29 18:02:00.645260: Epoch 787 
2025-11-29 18:02:00.645413: Current learning rate: 0.00385 
2025-11-29 18:03:59.380229: train_loss -0.7938 
2025-11-29 18:03:59.386266: val_loss -0.8247 
2025-11-29 18:03:59.386387: Pseudo dice [np.float32(0.9485), np.float32(0.884)] 
2025-11-29 18:03:59.387982: Epoch time: 118.74 s 
2025-11-29 18:04:04.194803:  
2025-11-29 18:04:04.194936: Epoch 788 
2025-11-29 18:04:04.194994: Current learning rate: 0.00386 
2025-11-29 18:06:03.561922: train_loss -0.7891 
2025-11-29 18:06:03.568178: val_loss -0.8135 
2025-11-29 18:06:03.568295: Pseudo dice [np.float32(0.9504), np.float32(0.8841)] 
2025-11-29 18:06:03.569621: Epoch time: 119.37 s 
2025-11-29 18:06:04.446893:  
2025-11-29 18:06:04.446975: Epoch 789 
2025-11-29 18:06:04.447124: Current learning rate: 0.00387 
2025-11-29 18:08:01.555420: train_loss -0.798 
2025-11-29 18:08:01.561387: val_loss -0.8184 
2025-11-29 18:08:01.561475: Pseudo dice [np.float32(0.944), np.float32(0.8726)] 
2025-11-29 18:08:01.562778: Epoch time: 117.11 s 
2025-11-29 18:08:02.454796:  
2025-11-29 18:08:02.455326: Epoch 790 
2025-11-29 18:08:02.455385: Current learning rate: 0.00388 
2025-11-29 18:10:01.313573: train_loss -0.7853 
2025-11-29 18:10:01.319990: val_loss -0.7682 
2025-11-29 18:10:01.320109: Pseudo dice [np.float32(0.949), np.float32(0.8531)] 
2025-11-29 18:10:01.321537: Epoch time: 118.86 s 
2025-11-29 18:10:02.256807:  
2025-11-29 18:10:02.256970: Epoch 791 
2025-11-29 18:10:02.257111: Current learning rate: 0.00389 
2025-11-29 18:12:00.858880: train_loss -0.8067 
2025-11-29 18:12:00.865458: val_loss -0.8155 
2025-11-29 18:12:00.865495: Pseudo dice [np.float32(0.954), np.float32(0.8721)] 
2025-11-29 18:12:00.866934: Epoch time: 118.61 s 
2025-11-29 18:12:01.731661:  
2025-11-29 18:12:01.731773: Epoch 792 
2025-11-29 18:12:01.731921: Current learning rate: 0.0039 
2025-11-29 18:13:59.489909: train_loss -0.8066 
2025-11-29 18:13:59.496820: val_loss -0.83 
2025-11-29 18:13:59.496966: Pseudo dice [np.float32(0.9549), np.float32(0.876)] 
2025-11-29 18:13:59.498530: Epoch time: 117.76 s 
2025-11-29 18:14:00.441536:  
2025-11-29 18:14:00.441606: Epoch 793 
2025-11-29 18:14:00.441751: Current learning rate: 0.0039 
2025-11-29 18:15:59.215023: train_loss -0.8034 
2025-11-29 18:15:59.220932: val_loss -0.7986 
2025-11-29 18:15:59.220964: Pseudo dice [np.float32(0.9556), np.float32(0.8921)] 
2025-11-29 18:15:59.222575: Epoch time: 118.78 s 
2025-11-29 18:16:00.050644:  
2025-11-29 18:16:00.050744: Epoch 794 
2025-11-29 18:16:00.050892: Current learning rate: 0.0039 
2025-11-29 18:17:58.085008: train_loss -0.7901 
2025-11-29 18:17:58.091570: val_loss -0.8106 
2025-11-29 18:17:58.091687: Pseudo dice [np.float32(0.9514), np.float32(0.8736)] 
2025-11-29 18:17:58.093247: Epoch time: 118.04 s 
2025-11-29 18:17:58.943767:  
2025-11-29 18:17:58.943920: Epoch 795 
2025-11-29 18:17:58.944064: Current learning rate: 0.00391 
2025-11-29 18:19:57.028523: train_loss -0.801 
2025-11-29 18:19:57.035239: val_loss -0.8132 
2025-11-29 18:19:57.035271: Pseudo dice [np.float32(0.9448), np.float32(0.8677)] 
2025-11-29 18:19:57.036860: Epoch time: 118.09 s 
2025-11-29 18:19:57.925720:  
2025-11-29 18:19:57.925812: Epoch 796 
2025-11-29 18:19:57.925959: Current learning rate: 0.00391 
2025-11-29 18:21:56.514138: train_loss -0.8093 
2025-11-29 18:21:56.520639: val_loss -0.815 
2025-11-29 18:21:56.520951: Pseudo dice [np.float32(0.953), np.float32(0.8843)] 
2025-11-29 18:21:56.522448: Epoch time: 118.59 s 
2025-11-29 18:21:57.375347:  
2025-11-29 18:21:57.375484: Epoch 797 
2025-11-29 18:21:57.375627: Current learning rate: 0.00391 
2025-11-29 18:23:56.756802: train_loss -0.8068 
2025-11-29 18:23:56.763520: val_loss -0.7916 
2025-11-29 18:23:56.763653: Pseudo dice [np.float32(0.9483), np.float32(0.8749)] 
2025-11-29 18:23:56.765214: Epoch time: 119.38 s 
2025-11-29 18:23:57.655452:  
2025-11-29 18:23:57.655531: Epoch 798 
2025-11-29 18:23:57.655670: Current learning rate: 0.00391 
2025-11-29 18:25:59.064232: train_loss -0.8041 
2025-11-29 18:25:59.084254: val_loss -0.8425 
2025-11-29 18:25:59.085403: Pseudo dice [np.float32(0.9566), np.float32(0.8864)] 
2025-11-29 18:25:59.097885: Epoch time: 121.41 s 
2025-11-29 18:26:01.508335:  
2025-11-29 18:26:01.508439: Epoch 799 
2025-11-29 18:26:01.508652: Current learning rate: 0.0039 
2025-11-29 18:28:00.980917: train_loss -0.8139 
2025-11-29 18:28:00.983323: val_loss -0.8153 
2025-11-29 18:28:00.983355: Pseudo dice [np.float32(0.952), np.float32(0.8791)] 
2025-11-29 18:28:00.984868: Epoch time: 119.48 s 
2025-11-29 18:28:04.415899:  
2025-11-29 18:28:04.415997: Epoch 800 
2025-11-29 18:28:04.416053: Current learning rate: 0.0039 
2025-11-29 18:30:02.261727: train_loss -0.8194 
2025-11-29 18:30:02.268336: val_loss -0.8314 
2025-11-29 18:30:02.268450: Pseudo dice [np.float32(0.9547), np.float32(0.8787)] 
2025-11-29 18:30:02.269877: Epoch time: 117.85 s 
2025-11-29 18:30:03.175457:  
2025-11-29 18:30:03.175572: Epoch 801 
2025-11-29 18:30:03.175726: Current learning rate: 0.00389 
2025-11-29 18:32:01.363986: train_loss -0.7934 
2025-11-29 18:32:01.370248: val_loss -0.8183 
2025-11-29 18:32:01.370364: Pseudo dice [np.float32(0.9516), np.float32(0.8769)] 
2025-11-29 18:32:01.371995: Epoch time: 118.19 s 
2025-11-29 18:32:02.291509:  
2025-11-29 18:32:02.291617: Epoch 802 
2025-11-29 18:32:02.291765: Current learning rate: 0.00388 
2025-11-29 18:34:01.063324: train_loss -0.8081 
2025-11-29 18:34:01.070060: val_loss -0.8048 
2025-11-29 18:34:01.070102: Pseudo dice [np.float32(0.9556), np.float32(0.8744)] 
2025-11-29 18:34:01.071630: Epoch time: 118.77 s 
2025-11-29 18:34:01.981643:  
2025-11-29 18:34:01.981735: Epoch 803 
2025-11-29 18:34:01.981879: Current learning rate: 0.00388 
2025-11-29 18:35:59.127815: train_loss -0.8044 
2025-11-29 18:35:59.131462: val_loss -0.7996 
2025-11-29 18:35:59.131580: Pseudo dice [np.float32(0.9605), np.float32(0.8932)] 
2025-11-29 18:35:59.132977: Epoch time: 117.15 s 
2025-11-29 18:35:59.988446:  
2025-11-29 18:35:59.988536: Epoch 804 
2025-11-29 18:35:59.988682: Current learning rate: 0.00387 
2025-11-29 18:37:59.786938: train_loss -0.8125 
2025-11-29 18:37:59.793181: val_loss -0.8099 
2025-11-29 18:37:59.793295: Pseudo dice [np.float32(0.9469), np.float32(0.8658)] 
2025-11-29 18:37:59.794803: Epoch time: 119.8 s 
2025-11-29 18:38:00.673398:  
2025-11-29 18:38:00.673517: Epoch 805 
2025-11-29 18:38:00.673674: Current learning rate: 0.00385 
2025-11-29 18:39:59.165021: train_loss -0.8187 
2025-11-29 18:39:59.171491: val_loss -0.8101 
2025-11-29 18:39:59.171608: Pseudo dice [np.float32(0.9517), np.float32(0.8759)] 
2025-11-29 18:39:59.173184: Epoch time: 118.49 s 
2025-11-29 18:40:00.055508:  
2025-11-29 18:40:00.055620: Epoch 806 
2025-11-29 18:40:00.055764: Current learning rate: 0.00384 
2025-11-29 18:41:58.458189: train_loss -0.8054 
2025-11-29 18:41:58.464121: val_loss -0.8284 
2025-11-29 18:41:58.464209: Pseudo dice [np.float32(0.956), np.float32(0.878)] 
2025-11-29 18:41:58.465839: Epoch time: 118.41 s 
2025-11-29 18:41:59.362003:  
2025-11-29 18:41:59.362093: Epoch 807 
2025-11-29 18:41:59.362227: Current learning rate: 0.00383 
2025-11-29 18:43:58.527129: train_loss -0.8044 
2025-11-29 18:43:58.533518: val_loss -0.8194 
2025-11-29 18:43:58.533637: Pseudo dice [np.float32(0.9508), np.float32(0.8829)] 
2025-11-29 18:43:58.535066: Epoch time: 119.17 s 
2025-11-29 18:43:59.420658:  
2025-11-29 18:43:59.420781: Epoch 808 
2025-11-29 18:43:59.420936: Current learning rate: 0.00381 
2025-11-29 18:46:01.637902: train_loss -0.8001 
2025-11-29 18:46:01.644194: val_loss -0.8183 
2025-11-29 18:46:01.644227: Pseudo dice [np.float32(0.9512), np.float32(0.8729)] 
2025-11-29 18:46:01.645811: Epoch time: 122.22 s 
2025-11-29 18:46:02.510846:  
2025-11-29 18:46:02.510941: Epoch 809 
2025-11-29 18:46:02.511122: Current learning rate: 0.0038 
2025-11-29 18:47:59.539930: train_loss -0.8165 
2025-11-29 18:47:59.545405: val_loss -0.7928 
2025-11-29 18:47:59.545435: Pseudo dice [np.float32(0.9567), np.float32(0.8885)] 
2025-11-29 18:47:59.546952: Epoch time: 117.03 s 
2025-11-29 18:48:00.431221:  
2025-11-29 18:48:00.431339: Epoch 810 
2025-11-29 18:48:00.431405: Current learning rate: 0.00378 
2025-11-29 18:50:01.879399: train_loss -0.7942 
2025-11-29 18:50:01.885941: val_loss -0.7895 
2025-11-29 18:50:01.886059: Pseudo dice [np.float32(0.9482), np.float32(0.8661)] 
2025-11-29 18:50:01.887520: Epoch time: 121.45 s 
2025-11-29 18:50:02.759758:  
2025-11-29 18:50:02.759873: Epoch 811 
2025-11-29 18:50:02.760051: Current learning rate: 0.00376 
2025-11-29 18:52:01.668236: train_loss -0.8065 
2025-11-29 18:52:01.674827: val_loss -0.7905 
2025-11-29 18:52:01.674946: Pseudo dice [np.float32(0.9506), np.float32(0.878)] 
2025-11-29 18:52:01.676482: Epoch time: 118.91 s 
2025-11-29 18:52:02.548441:  
2025-11-29 18:52:02.548537: Epoch 812 
2025-11-29 18:52:02.548684: Current learning rate: 0.00374 
2025-11-29 18:54:00.289761: train_loss -0.7983 
2025-11-29 18:54:00.296247: val_loss -0.8044 
2025-11-29 18:54:00.296368: Pseudo dice [np.float32(0.9528), np.float32(0.8633)] 
2025-11-29 18:54:00.297960: Epoch time: 117.74 s 
2025-11-29 18:54:01.205509:  
2025-11-29 18:54:01.205595: Epoch 813 
2025-11-29 18:54:01.205746: Current learning rate: 0.00372 
2025-11-29 18:55:59.383667: train_loss -0.8061 
2025-11-29 18:55:59.389515: val_loss -0.8369 
2025-11-29 18:55:59.389628: Pseudo dice [np.float32(0.9554), np.float32(0.8984)] 
2025-11-29 18:55:59.391382: Epoch time: 118.18 s 
2025-11-29 18:56:00.281813:  
2025-11-29 18:56:00.281909: Epoch 814 
2025-11-29 18:56:00.282064: Current learning rate: 0.0037 
2025-11-29 18:57:58.819020: train_loss -0.7809 
2025-11-29 18:57:58.825300: val_loss -0.7484 
2025-11-29 18:57:58.825596: Pseudo dice [np.float32(0.9444), np.float32(0.8642)] 
2025-11-29 18:57:58.827219: Epoch time: 118.54 s 
2025-11-29 18:57:59.690468:  
2025-11-29 18:57:59.690902: Epoch 815 
2025-11-29 18:57:59.691045: Current learning rate: 0.00367 
2025-11-29 18:59:58.191029: train_loss -0.7889 
2025-11-29 18:59:58.197749: val_loss -0.7918 
2025-11-29 18:59:58.198040: Pseudo dice [np.float32(0.9498), np.float32(0.8707)] 
2025-11-29 18:59:58.199562: Epoch time: 118.5 s 
2025-11-29 18:59:59.101631:  
2025-11-29 18:59:59.101723: Epoch 816 
2025-11-29 18:59:59.101889: Current learning rate: 0.00365 
2025-11-29 19:01:55.965108: train_loss -0.7995 
2025-11-29 19:01:55.971607: val_loss -0.8184 
2025-11-29 19:01:55.971731: Pseudo dice [np.float32(0.9548), np.float32(0.8743)] 
2025-11-29 19:01:55.973252: Epoch time: 116.87 s 
2025-11-29 19:01:56.817438:  
2025-11-29 19:01:56.817544: Epoch 817 
2025-11-29 19:01:56.817606: Current learning rate: 0.00362 
2025-11-29 19:03:56.133712: train_loss -0.802 
2025-11-29 19:03:56.140450: val_loss -0.8254 
2025-11-29 19:03:56.140567: Pseudo dice [np.float32(0.9524), np.float32(0.8679)] 
2025-11-29 19:03:56.142060: Epoch time: 119.32 s 
2025-11-29 19:03:57.008408:  
2025-11-29 19:03:57.008554: Epoch 818 
2025-11-29 19:03:57.008698: Current learning rate: 0.0036 
2025-11-29 19:05:55.874537: train_loss -0.802 
2025-11-29 19:05:55.880794: val_loss -0.8022 
2025-11-29 19:05:55.880991: Pseudo dice [np.float32(0.9507), np.float32(0.8575)] 
2025-11-29 19:05:55.882364: Epoch time: 118.87 s 
2025-11-29 19:06:00.820328:  
2025-11-29 19:06:00.820464: Epoch 819 
2025-11-29 19:06:00.820521: Current learning rate: 0.00357 
2025-11-29 19:08:00.189850: train_loss -0.7967 
2025-11-29 19:08:00.196802: val_loss -0.7851 
2025-11-29 19:08:00.196982: Pseudo dice [np.float32(0.9565), np.float32(0.8778)] 
2025-11-29 19:08:00.198401: Epoch time: 119.37 s 
2025-11-29 19:08:01.086226:  
2025-11-29 19:08:01.086356: Epoch 820 
2025-11-29 19:08:01.086504: Current learning rate: 0.00354 
2025-11-29 19:10:00.506575: train_loss -0.7924 
2025-11-29 19:10:00.513470: val_loss -0.8197 
2025-11-29 19:10:00.513659: Pseudo dice [np.float32(0.9532), np.float32(0.88)] 
2025-11-29 19:10:00.515221: Epoch time: 119.42 s 
2025-11-29 19:10:01.380178:  
2025-11-29 19:10:01.380275: Epoch 821 
2025-11-29 19:10:01.380417: Current learning rate: 0.00351 
2025-11-29 19:11:58.182187: train_loss -0.7856 
2025-11-29 19:11:58.188115: val_loss -0.8107 
2025-11-29 19:11:58.188156: Pseudo dice [np.float32(0.9429), np.float32(0.8582)] 
2025-11-29 19:11:58.189643: Epoch time: 116.8 s 
2025-11-29 19:11:59.040970:  
2025-11-29 19:11:59.041076: Epoch 822 
2025-11-29 19:11:59.041132: Current learning rate: 0.00348 
2025-11-29 19:13:59.616714: train_loss -0.7852 
2025-11-29 19:13:59.623193: val_loss -0.7984 
2025-11-29 19:13:59.623307: Pseudo dice [np.float32(0.9542), np.float32(0.8755)] 
2025-11-29 19:13:59.624752: Epoch time: 120.58 s 
2025-11-29 19:14:00.505867:  
2025-11-29 19:14:00.505953: Epoch 823 
2025-11-29 19:14:00.506101: Current learning rate: 0.00345 
2025-11-29 19:15:58.680494: train_loss -0.795 
2025-11-29 19:15:58.686357: val_loss -0.7965 
2025-11-29 19:15:58.686473: Pseudo dice [np.float32(0.9488), np.float32(0.8603)] 
2025-11-29 19:15:58.687828: Epoch time: 118.18 s 
2025-11-29 19:15:59.529317:  
2025-11-29 19:15:59.529511: Epoch 824 
2025-11-29 19:15:59.529648: Current learning rate: 0.00341 
2025-11-29 19:17:58.808429: train_loss -0.8061 
2025-11-29 19:17:58.814699: val_loss -0.8124 
2025-11-29 19:17:58.814729: Pseudo dice [np.float32(0.9423), np.float32(0.8665)] 
2025-11-29 19:17:58.816126: Epoch time: 119.28 s 
2025-11-29 19:17:59.714419:  
2025-11-29 19:17:59.714552: Epoch 825 
2025-11-29 19:17:59.714701: Current learning rate: 0.00338 
2025-11-29 19:19:59.725119: train_loss -0.8018 
2025-11-29 19:19:59.731262: val_loss -0.821 
2025-11-29 19:19:59.731380: Pseudo dice [np.float32(0.9526), np.float32(0.895)] 
2025-11-29 19:19:59.733029: Epoch time: 120.01 s 
2025-11-29 19:20:00.621793:  
2025-11-29 19:20:00.622233: Epoch 826 
2025-11-29 19:20:00.622386: Current learning rate: 0.00335 
2025-11-29 19:21:58.662670: train_loss -0.8072 
2025-11-29 19:21:58.668780: val_loss -0.8002 
2025-11-29 19:21:58.668895: Pseudo dice [np.float32(0.9533), np.float32(0.8813)] 
2025-11-29 19:21:58.670446: Epoch time: 118.04 s 
2025-11-29 19:21:59.546895:  
2025-11-29 19:21:59.546994: Epoch 827 
2025-11-29 19:21:59.547145: Current learning rate: 0.00331 
2025-11-29 19:23:57.738473: train_loss -0.7983 
2025-11-29 19:23:57.744693: val_loss -0.804 
2025-11-29 19:23:57.744816: Pseudo dice [np.float32(0.9525), np.float32(0.8858)] 
2025-11-29 19:23:57.746270: Epoch time: 118.19 s 
2025-11-29 19:23:58.580635:  
2025-11-29 19:23:58.580738: Epoch 828 
2025-11-29 19:23:58.580905: Current learning rate: 0.00327 
2025-11-29 19:25:56.881383: train_loss -0.7916 
2025-11-29 19:25:56.887558: val_loss -0.7665 
2025-11-29 19:25:56.887676: Pseudo dice [np.float32(0.9436), np.float32(0.8631)] 
2025-11-29 19:25:56.889239: Epoch time: 118.3 s 
2025-11-29 19:25:57.749084:  
2025-11-29 19:25:57.749210: Epoch 829 
2025-11-29 19:25:57.749352: Current learning rate: 0.00324 
2025-11-29 19:27:56.805904: train_loss -0.8031 
2025-11-29 19:27:56.812459: val_loss -0.7911 
2025-11-29 19:27:56.812581: Pseudo dice [np.float32(0.9507), np.float32(0.8796)] 
2025-11-29 19:27:56.814161: Epoch time: 119.06 s 
2025-11-29 19:27:57.674809:  
2025-11-29 19:27:57.674907: Epoch 830 
2025-11-29 19:27:57.675131: Current learning rate: 0.0032 
2025-11-29 19:30:00.182992: train_loss -0.8089 
2025-11-29 19:30:00.189419: val_loss -0.8027 
2025-11-29 19:30:00.189530: Pseudo dice [np.float32(0.9523), np.float32(0.8721)] 
2025-11-29 19:30:00.190925: Epoch time: 122.51 s 
2025-11-29 19:30:01.070643:  
2025-11-29 19:30:01.070745: Epoch 831 
2025-11-29 19:30:01.070884: Current learning rate: 0.00316 
2025-11-29 19:32:00.069800: train_loss -0.8089 
2025-11-29 19:32:00.076246: val_loss -0.8186 
2025-11-29 19:32:00.076292: Pseudo dice [np.float32(0.948), np.float32(0.8599)] 
2025-11-29 19:32:00.077710: Epoch time: 119.0 s 
2025-11-29 19:32:00.947608:  
2025-11-29 19:32:00.947729: Epoch 832 
2025-11-29 19:32:00.947872: Current learning rate: 0.00312 
2025-11-29 19:33:59.267617: train_loss -0.7989 
2025-11-29 19:33:59.274494: val_loss -0.8278 
2025-11-29 19:33:59.274529: Pseudo dice [np.float32(0.9536), np.float32(0.8836)] 
2025-11-29 19:33:59.276053: Epoch time: 118.32 s 
2025-11-29 19:34:00.127465:  
2025-11-29 19:34:00.127732: Epoch 833 
2025-11-29 19:34:00.127877: Current learning rate: 0.00308 
2025-11-29 19:35:58.042576: train_loss -0.8025 
2025-11-29 19:35:58.048914: val_loss -0.7844 
2025-11-29 19:35:58.049033: Pseudo dice [np.float32(0.954), np.float32(0.8941)] 
2025-11-29 19:35:58.050415: Epoch time: 117.92 s 
2025-11-29 19:35:58.925991:  
2025-11-29 19:35:58.926091: Epoch 834 
2025-11-29 19:35:58.926237: Current learning rate: 0.00304 
2025-11-29 19:37:57.670936: train_loss -0.8011 
2025-11-29 19:37:57.676956: val_loss -0.7925 
2025-11-29 19:37:57.677073: Pseudo dice [np.float32(0.951), np.float32(0.8696)] 
2025-11-29 19:37:57.678600: Epoch time: 118.75 s 
2025-11-29 19:37:58.548808:  
2025-11-29 19:37:58.548921: Epoch 835 
2025-11-29 19:37:58.549066: Current learning rate: 0.003 
2025-11-29 19:39:57.256427: train_loss -0.8167 
2025-11-29 19:39:57.262074: val_loss -0.8327 
2025-11-29 19:39:57.262166: Pseudo dice [np.float32(0.9536), np.float32(0.8828)] 
2025-11-29 19:39:57.263695: Epoch time: 118.71 s 
2025-11-29 19:39:58.162077:  
2025-11-29 19:39:58.162187: Epoch 836 
2025-11-29 19:39:58.162327: Current learning rate: 0.00296 
2025-11-29 19:41:57.241181: train_loss -0.814 
2025-11-29 19:41:57.247987: val_loss -0.8168 
2025-11-29 19:41:57.248108: Pseudo dice [np.float32(0.9546), np.float32(0.8747)] 
2025-11-29 19:41:57.249650: Epoch time: 119.08 s 
2025-11-29 19:41:58.117489:  
2025-11-29 19:41:58.117633: Epoch 837 
2025-11-29 19:41:58.117823: Current learning rate: 0.00292 
2025-11-29 19:43:56.076787: train_loss -0.8108 
2025-11-29 19:43:56.083089: val_loss -0.8261 
2025-11-29 19:43:56.083205: Pseudo dice [np.float32(0.9556), np.float32(0.8945)] 
2025-11-29 19:43:56.084706: Epoch time: 117.96 s 
2025-11-29 19:43:56.936719:  
2025-11-29 19:43:56.936817: Epoch 838 
2025-11-29 19:43:56.936962: Current learning rate: 0.00288 
2025-11-29 19:45:54.734797: train_loss -0.8013 
2025-11-29 19:45:54.740936: val_loss -0.8341 
2025-11-29 19:45:54.741051: Pseudo dice [np.float32(0.9479), np.float32(0.8853)] 
2025-11-29 19:45:54.742488: Epoch time: 117.8 s 
2025-11-29 19:45:55.643474:  
2025-11-29 19:45:55.643626: Epoch 839 
2025-11-29 19:45:55.643767: Current learning rate: 0.00283 
2025-11-29 19:47:53.960629: train_loss -0.8095 
2025-11-29 19:47:53.967875: val_loss -0.8035 
2025-11-29 19:47:53.968177: Pseudo dice [np.float32(0.9463), np.float32(0.8869)] 
2025-11-29 19:47:53.969755: Epoch time: 118.32 s 
2025-11-29 19:47:54.852450:  
2025-11-29 19:47:54.852573: Epoch 840 
2025-11-29 19:47:54.852741: Current learning rate: 0.00279 
2025-11-29 19:49:52.135069: train_loss -0.8067 
2025-11-29 19:49:52.140762: val_loss -0.8323 
2025-11-29 19:49:52.140879: Pseudo dice [np.float32(0.9552), np.float32(0.8856)] 
2025-11-29 19:49:52.142271: Epoch time: 117.29 s 
2025-11-29 19:49:52.982780:  
2025-11-29 19:49:52.982888: Epoch 841 
2025-11-29 19:49:52.983028: Current learning rate: 0.00275 
2025-11-29 19:51:52.824607: train_loss -0.8101 
2025-11-29 19:51:52.830941: val_loss -0.8273 
2025-11-29 19:51:52.831064: Pseudo dice [np.float32(0.9516), np.float32(0.8755)] 
2025-11-29 19:51:52.832686: Epoch time: 119.84 s 
2025-11-29 19:51:57.623225:  
2025-11-29 19:51:57.623330: Epoch 842 
2025-11-29 19:51:57.623393: Current learning rate: 0.0027 
2025-11-29 19:53:56.725672: train_loss -0.8138 
2025-11-29 19:53:56.732076: val_loss -0.8084 
2025-11-29 19:53:56.732189: Pseudo dice [np.float32(0.9546), np.float32(0.878)] 
2025-11-29 19:53:56.733562: Epoch time: 119.1 s 
2025-11-29 19:53:57.648176:  
2025-11-29 19:53:57.648289: Epoch 843 
2025-11-29 19:53:57.648434: Current learning rate: 0.00266 
2025-11-29 19:55:55.845937: train_loss -0.812 
2025-11-29 19:55:55.851943: val_loss -0.7727 
2025-11-29 19:55:55.852062: Pseudo dice [np.float32(0.9546), np.float32(0.8666)] 
2025-11-29 19:55:55.853686: Epoch time: 118.2 s 
2025-11-29 19:55:56.697944:  
2025-11-29 19:55:56.698052: Epoch 844 
2025-11-29 19:55:56.698198: Current learning rate: 0.00261 
2025-11-29 19:57:55.615361: train_loss -0.8147 
2025-11-29 19:57:55.621572: val_loss -0.8207 
2025-11-29 19:57:55.621689: Pseudo dice [np.float32(0.9515), np.float32(0.8789)] 
2025-11-29 19:57:55.623103: Epoch time: 118.92 s 
2025-11-29 19:57:56.506610:  
2025-11-29 19:57:56.507127: Epoch 845 
2025-11-29 19:57:56.507267: Current learning rate: 0.00257 
2025-11-29 19:59:55.825982: train_loss -0.803 
2025-11-29 19:59:55.832591: val_loss -0.8156 
2025-11-29 19:59:55.832678: Pseudo dice [np.float32(0.9449), np.float32(0.8675)] 
2025-11-29 19:59:55.834174: Epoch time: 119.32 s 
2025-11-29 19:59:56.737074:  
2025-11-29 19:59:56.737203: Epoch 846 
2025-11-29 19:59:56.737346: Current learning rate: 0.00252 
2025-11-29 20:01:54.778578: train_loss -0.8034 
2025-11-29 20:01:54.784907: val_loss -0.8151 
2025-11-29 20:01:54.785019: Pseudo dice [np.float32(0.9576), np.float32(0.8884)] 
2025-11-29 20:01:54.786579: Epoch time: 118.04 s 
2025-11-29 20:01:55.671690:  
2025-11-29 20:01:55.672464: Epoch 847 
2025-11-29 20:01:55.672625: Current learning rate: 0.00247 
2025-11-29 20:03:55.102813: train_loss -0.8276 
2025-11-29 20:03:55.109180: val_loss -0.8073 
2025-11-29 20:03:55.109296: Pseudo dice [np.float32(0.9573), np.float32(0.8891)] 
2025-11-29 20:03:55.110909: Epoch time: 119.43 s 
2025-11-29 20:03:55.987723:  
2025-11-29 20:03:55.988007: Epoch 848 
2025-11-29 20:03:55.988148: Current learning rate: 0.00243 
2025-11-29 20:05:53.813143: train_loss -0.8179 
2025-11-29 20:05:53.819170: val_loss -0.8223 
2025-11-29 20:05:53.819297: Pseudo dice [np.float32(0.9533), np.float32(0.8789)] 
2025-11-29 20:05:53.820785: Epoch time: 117.83 s 
2025-11-29 20:05:54.686976:  
2025-11-29 20:05:54.687085: Epoch 849 
2025-11-29 20:05:54.687232: Current learning rate: 0.00238 
2025-11-29 20:07:53.890530: train_loss -0.8169 
2025-11-29 20:07:53.897557: val_loss -0.8107 
2025-11-29 20:07:53.897674: Pseudo dice [np.float32(0.955), np.float32(0.8801)] 
2025-11-29 20:07:53.899297: Epoch time: 119.21 s 
2025-11-29 20:07:57.344708:  
2025-11-29 20:07:57.344869: Epoch 850 
2025-11-29 20:07:57.344962: Current learning rate: 0.00234 
2025-11-29 20:09:55.718666: train_loss -0.8067 
2025-11-29 20:09:55.724554: val_loss -0.7874 
2025-11-29 20:09:55.724669: Pseudo dice [np.float32(0.9568), np.float32(0.8813)] 
2025-11-29 20:09:55.726143: Epoch time: 118.39 s 
2025-11-29 20:09:56.602721:  
2025-11-29 20:09:56.602838: Epoch 851 
2025-11-29 20:09:56.602985: Current learning rate: 0.00229 
2025-11-29 20:11:55.040679: train_loss -0.8165 
2025-11-29 20:11:55.046947: val_loss -0.8432 
2025-11-29 20:11:55.047074: Pseudo dice [np.float32(0.9526), np.float32(0.8771)] 
2025-11-29 20:11:55.048611: Epoch time: 118.44 s 
2025-11-29 20:11:55.971719:  
2025-11-29 20:11:55.971829: Epoch 852 
2025-11-29 20:11:55.971969: Current learning rate: 0.00224 
2025-11-29 20:13:55.264010: train_loss -0.8144 
2025-11-29 20:13:55.270223: val_loss -0.8064 
2025-11-29 20:13:55.270306: Pseudo dice [np.float32(0.9478), np.float32(0.868)] 
2025-11-29 20:13:55.271780: Epoch time: 119.29 s 
2025-11-29 20:14:00.135654:  
2025-11-29 20:14:00.135780: Epoch 853 
2025-11-29 20:14:00.135839: Current learning rate: 0.0022 
2025-11-29 20:15:59.500396: train_loss -0.8226 
2025-11-29 20:15:59.507222: val_loss -0.8451 
2025-11-29 20:15:59.507357: Pseudo dice [np.float32(0.954), np.float32(0.882)] 
2025-11-29 20:15:59.508994: Epoch time: 119.36 s 
2025-11-29 20:16:00.364331:  
2025-11-29 20:16:00.364404: Epoch 854 
2025-11-29 20:16:00.364544: Current learning rate: 0.00215 
2025-11-29 20:17:59.023089: train_loss -0.8117 
2025-11-29 20:17:59.030006: val_loss -0.8163 
2025-11-29 20:17:59.030122: Pseudo dice [np.float32(0.9567), np.float32(0.8794)] 
2025-11-29 20:17:59.031689: Epoch time: 118.66 s 
2025-11-29 20:17:59.912651:  
2025-11-29 20:17:59.912766: Epoch 855 
2025-11-29 20:17:59.912902: Current learning rate: 0.0021 
2025-11-29 20:19:58.168259: train_loss -0.8196 
2025-11-29 20:19:58.174741: val_loss -0.8196 
2025-11-29 20:19:58.174777: Pseudo dice [np.float32(0.9523), np.float32(0.8836)] 
2025-11-29 20:19:58.176242: Epoch time: 118.26 s 
2025-11-29 20:19:59.073143:  
2025-11-29 20:19:59.073607: Epoch 856 
2025-11-29 20:19:59.073761: Current learning rate: 0.00206 
2025-11-29 20:21:57.884721: train_loss -0.8244 
2025-11-29 20:21:57.890660: val_loss -0.8363 
2025-11-29 20:21:57.890694: Pseudo dice [np.float32(0.9554), np.float32(0.8759)] 
2025-11-29 20:21:57.892255: Epoch time: 118.82 s 
2025-11-29 20:21:58.784076:  
2025-11-29 20:21:58.784210: Epoch 857 
2025-11-29 20:21:58.784354: Current learning rate: 0.00201 
2025-11-29 20:23:57.890624: train_loss -0.8187 
2025-11-29 20:23:57.896950: val_loss -0.8134 
2025-11-29 20:23:57.897071: Pseudo dice [np.float32(0.956), np.float32(0.8916)] 
2025-11-29 20:23:57.898648: Epoch time: 119.11 s 
2025-11-29 20:23:58.793117:  
2025-11-29 20:23:58.793241: Epoch 858 
2025-11-29 20:23:58.793386: Current learning rate: 0.00196 
2025-11-29 20:25:56.965763: train_loss -0.8093 
2025-11-29 20:25:56.972625: val_loss -0.8051 
2025-11-29 20:25:56.972747: Pseudo dice [np.float32(0.9538), np.float32(0.8805)] 
2025-11-29 20:25:56.974242: Epoch time: 118.18 s 
2025-11-29 20:25:57.845532:  
2025-11-29 20:25:57.845831: Epoch 859 
2025-11-29 20:25:57.845983: Current learning rate: 0.00192 
2025-11-29 20:27:57.114273: train_loss -0.8086 
2025-11-29 20:27:57.120976: val_loss -0.8061 
2025-11-29 20:27:57.121094: Pseudo dice [np.float32(0.9591), np.float32(0.8918)] 
2025-11-29 20:27:57.122481: Epoch time: 119.27 s 
2025-11-29 20:27:58.014722:  
2025-11-29 20:27:58.014805: Epoch 860 
2025-11-29 20:27:58.014945: Current learning rate: 0.00187 
2025-11-29 20:29:56.379693: train_loss -0.814 
2025-11-29 20:29:56.386193: val_loss -0.8402 
2025-11-29 20:29:56.386308: Pseudo dice [np.float32(0.9551), np.float32(0.8897)] 
2025-11-29 20:29:56.387771: Epoch time: 118.37 s 
2025-11-29 20:29:57.271553:  
2025-11-29 20:29:57.271684: Epoch 861 
2025-11-29 20:29:57.271838: Current learning rate: 0.00182 
2025-11-29 20:31:54.895437: train_loss -0.7985 
2025-11-29 20:31:54.901669: val_loss -0.8294 
2025-11-29 20:31:54.901759: Pseudo dice [np.float32(0.954), np.float32(0.8921)] 
2025-11-29 20:31:54.903261: Epoch time: 117.63 s 
2025-11-29 20:31:55.795827:  
2025-11-29 20:31:55.795912: Epoch 862 
2025-11-29 20:31:55.796054: Current learning rate: 0.00178 
2025-11-29 20:33:54.693211: train_loss -0.8144 
2025-11-29 20:33:54.699577: val_loss -0.8333 
2025-11-29 20:33:54.699747: Pseudo dice [np.float32(0.9623), np.float32(0.9012)] 
2025-11-29 20:33:54.701363: Epoch time: 118.9 s 
2025-11-29 20:33:55.598618:  
2025-11-29 20:33:55.598717: Epoch 863 
2025-11-29 20:33:55.598863: Current learning rate: 0.00173 
2025-11-29 20:35:54.049043: train_loss -0.8062 
2025-11-29 20:35:54.055730: val_loss -0.8416 
2025-11-29 20:35:54.055764: Pseudo dice [np.float32(0.9533), np.float32(0.8888)] 
2025-11-29 20:35:54.057287: Epoch time: 118.45 s 
2025-11-29 20:35:54.885006:  
2025-11-29 20:35:54.885089: Epoch 864 
2025-11-29 20:35:54.885264: Current learning rate: 0.00169 
2025-11-29 20:37:57.700671: train_loss -0.802 
2025-11-29 20:37:57.707528: val_loss -0.816 
2025-11-29 20:37:57.707733: Pseudo dice [np.float32(0.9532), np.float32(0.8836)] 
2025-11-29 20:37:57.709277: Epoch time: 122.82 s 
2025-11-29 20:37:58.600703:  
2025-11-29 20:37:58.600804: Epoch 865 
2025-11-29 20:37:58.600943: Current learning rate: 0.00164 
2025-11-29 20:39:57.178619: train_loss -0.8027 
2025-11-29 20:39:57.184408: val_loss -0.8509 
2025-11-29 20:39:57.184532: Pseudo dice [np.float32(0.9539), np.float32(0.8837)] 
2025-11-29 20:39:57.186018: Epoch time: 118.58 s 
2025-11-29 20:39:58.098036:  
2025-11-29 20:39:58.098159: Epoch 866 
2025-11-29 20:39:58.098307: Current learning rate: 0.0016 
2025-11-29 20:41:58.712979: train_loss -0.8101 
2025-11-29 20:41:58.717363: val_loss -0.8654 
2025-11-29 20:41:58.717398: Pseudo dice [np.float32(0.9608), np.float32(0.8933)] 
2025-11-29 20:41:58.718817: Epoch time: 120.62 s 
2025-11-29 20:41:59.547173:  
2025-11-29 20:41:59.547318: Epoch 867 
2025-11-29 20:41:59.547458: Current learning rate: 0.00155 
2025-11-29 20:43:57.457001: train_loss -0.8307 
2025-11-29 20:43:57.463002: val_loss -0.8149 
2025-11-29 20:43:57.463117: Pseudo dice [np.float32(0.9562), np.float32(0.8841)] 
2025-11-29 20:43:57.464530: Epoch time: 117.91 s 
2025-11-29 20:43:58.328511:  
2025-11-29 20:43:58.328620: Epoch 868 
2025-11-29 20:43:58.328773: Current learning rate: 0.00151 
2025-11-29 20:45:57.472349: train_loss -0.8107 
2025-11-29 20:45:57.482705: val_loss -0.8422 
2025-11-29 20:45:57.482779: Pseudo dice [np.float32(0.9574), np.float32(0.886)] 
2025-11-29 20:45:57.484301: Epoch time: 119.15 s 
2025-11-29 20:45:58.386543:  
2025-11-29 20:45:58.387017: Epoch 869 
2025-11-29 20:45:58.387452: Current learning rate: 0.00146 
2025-11-29 20:47:55.571754: train_loss -0.8188 
2025-11-29 20:47:55.577238: val_loss -0.8272 
2025-11-29 20:47:55.577351: Pseudo dice [np.float32(0.9553), np.float32(0.8853)] 
2025-11-29 20:47:55.578841: Epoch time: 117.19 s 
2025-11-29 20:47:56.420950:  
2025-11-29 20:47:56.421046: Epoch 870 
2025-11-29 20:47:56.421188: Current learning rate: 0.00142 
2025-11-29 20:49:55.130564: train_loss -0.8205 
2025-11-29 20:49:55.136342: val_loss -0.8221 
2025-11-29 20:49:55.136464: Pseudo dice [np.float32(0.9561), np.float32(0.8815)] 
2025-11-29 20:49:55.137949: Epoch time: 118.71 s 
2025-11-29 20:49:55.966276:  
2025-11-29 20:49:55.966616: Epoch 871 
2025-11-29 20:49:55.966763: Current learning rate: 0.00138 
2025-11-29 20:51:54.449815: train_loss -0.8325 
2025-11-29 20:51:54.456644: val_loss -0.8493 
2025-11-29 20:51:54.456678: Pseudo dice [np.float32(0.9573), np.float32(0.8957)] 
2025-11-29 20:51:54.458237: Epoch time: 118.49 s 
2025-11-29 20:51:55.314228:  
2025-11-29 20:51:55.314330: Epoch 872 
2025-11-29 20:51:55.314466: Current learning rate: 0.00133 
2025-11-29 20:53:54.142617: train_loss -0.836 
2025-11-29 20:53:54.149114: val_loss -0.8052 
2025-11-29 20:53:54.149231: Pseudo dice [np.float32(0.9574), np.float32(0.8918)] 
2025-11-29 20:53:54.150557: Epoch time: 118.83 s 
2025-11-29 20:53:55.038920:  
2025-11-29 20:53:55.039061: Epoch 873 
2025-11-29 20:53:55.039204: Current learning rate: 0.00129 
2025-11-29 20:55:53.694307: train_loss -0.8148 
2025-11-29 20:55:53.700849: val_loss -0.8232 
2025-11-29 20:55:53.700884: Pseudo dice [np.float32(0.9555), np.float32(0.8806)] 
2025-11-29 20:55:53.702416: Epoch time: 118.66 s 
2025-11-29 20:55:54.551384:  
2025-11-29 20:55:54.551496: Epoch 874 
2025-11-29 20:55:54.551634: Current learning rate: 0.00125 
2025-11-29 20:57:53.487724: train_loss -0.83 
2025-11-29 20:57:53.493918: val_loss -0.8407 
2025-11-29 20:57:53.494036: Pseudo dice [np.float32(0.9552), np.float32(0.8849)] 
2025-11-29 20:57:53.495476: Epoch time: 118.94 s 
2025-11-29 20:57:54.366032:  
2025-11-29 20:57:54.366126: Epoch 875 
2025-11-29 20:57:54.366512: Current learning rate: 0.00121 
2025-11-29 20:59:52.370202: train_loss -0.8292 
2025-11-29 20:59:52.377058: val_loss -0.8173 
2025-11-29 20:59:52.377172: Pseudo dice [np.float32(0.9591), np.float32(0.8913)] 
2025-11-29 20:59:52.378741: Epoch time: 118.01 s 
2025-11-29 20:59:57.254025:  
2025-11-29 20:59:57.254134: Epoch 876 
2025-11-29 20:59:57.254192: Current learning rate: 0.00117 
2025-11-29 21:01:55.771240: train_loss -0.8151 
2025-11-29 21:01:55.778159: val_loss -0.8386 
2025-11-29 21:01:55.778276: Pseudo dice [np.float32(0.9542), np.float32(0.8869)] 
2025-11-29 21:01:55.779687: Epoch time: 118.52 s 
2025-11-29 21:01:56.646373:  
2025-11-29 21:01:56.646487: Epoch 877 
2025-11-29 21:01:56.646678: Current learning rate: 0.00113 
2025-11-29 21:03:53.743350: train_loss -0.8156 
2025-11-29 21:03:53.746622: val_loss -0.843 
2025-11-29 21:03:53.746654: Pseudo dice [np.float32(0.9595), np.float32(0.9012)] 
2025-11-29 21:03:53.747839: Epoch time: 117.1 s 
2025-11-29 21:03:53.747906: Yayy! New best EMA pseudo Dice: 0.9222000241279602 
2025-11-29 21:03:55.794166:  
2025-11-29 21:03:55.794269: Epoch 878 
2025-11-29 21:03:55.794331: Current learning rate: 0.00109 
2025-11-29 21:05:54.968348: train_loss -0.8187 
2025-11-29 21:05:54.974971: val_loss -0.8242 
2025-11-29 21:05:54.975087: Pseudo dice [np.float32(0.9569), np.float32(0.8864)] 
2025-11-29 21:05:54.976444: Epoch time: 119.18 s 
2025-11-29 21:05:55.832088:  
2025-11-29 21:05:55.832191: Epoch 879 
2025-11-29 21:05:55.832338: Current learning rate: 0.00105 
2025-11-29 21:07:53.958623: train_loss -0.822 
2025-11-29 21:07:53.965123: val_loss -0.7867 
2025-11-29 21:07:53.965240: Pseudo dice [np.float32(0.9561), np.float32(0.8923)] 
2025-11-29 21:07:53.966681: Epoch time: 118.13 s 
2025-11-29 21:07:53.966756: Yayy! New best EMA pseudo Dice: 0.9222999811172485 
2025-11-29 21:07:55.934682:  
2025-11-29 21:07:55.934882: Epoch 880 
2025-11-29 21:07:55.934942: Current learning rate: 0.00101 
2025-11-29 21:09:53.934780: train_loss -0.8151 
2025-11-29 21:09:53.941862: val_loss -0.8504 
2025-11-29 21:09:53.941987: Pseudo dice [np.float32(0.9599), np.float32(0.8937)] 
2025-11-29 21:09:53.943559: Epoch time: 118.0 s 
2025-11-29 21:09:53.943640: Yayy! New best EMA pseudo Dice: 0.9228000044822693 
2025-11-29 21:09:57.215407:  
2025-11-29 21:09:57.215595: Epoch 881 
2025-11-29 21:09:57.215663: Current learning rate: 0.00097 
2025-11-29 21:11:55.571258: train_loss -0.8303 
2025-11-29 21:11:55.577757: val_loss -0.8277 
2025-11-29 21:11:55.577796: Pseudo dice [np.float32(0.9557), np.float32(0.8936)] 
2025-11-29 21:11:55.579322: Epoch time: 118.36 s 
2025-11-29 21:11:55.579387: Yayy! New best EMA pseudo Dice: 0.9229999780654907 
2025-11-29 21:11:59.270217:  
2025-11-29 21:11:59.270323: Epoch 882 
2025-11-29 21:11:59.270377: Current learning rate: 0.00094 
2025-11-29 21:13:56.621788: train_loss -0.8082 
2025-11-29 21:13:56.625476: val_loss -0.8467 
2025-11-29 21:13:56.625515: Pseudo dice [np.float32(0.963), np.float32(0.8954)] 
2025-11-29 21:13:56.626743: Epoch time: 117.37 s 
2025-11-29 21:13:56.626766: Yayy! New best EMA pseudo Dice: 0.9236000180244446 
2025-11-29 21:14:00.434767:  
2025-11-29 21:14:00.435036: Epoch 883 
2025-11-29 21:14:00.435186: Current learning rate: 0.0009 
2025-11-29 21:15:59.914984: train_loss -0.8294 
2025-11-29 21:15:59.920578: val_loss -0.8123 
2025-11-29 21:15:59.920690: Pseudo dice [np.float32(0.95), np.float32(0.8751)] 
2025-11-29 21:15:59.922207: Epoch time: 119.51 s 
2025-11-29 21:16:00.784295:  
2025-11-29 21:16:00.784395: Epoch 884 
2025-11-29 21:16:00.784549: Current learning rate: 0.00086 
2025-11-29 21:17:59.059332: train_loss -0.8268 
2025-11-29 21:17:59.065453: val_loss -0.8183 
2025-11-29 21:17:59.065571: Pseudo dice [np.float32(0.9541), np.float32(0.8859)] 
2025-11-29 21:17:59.067296: Epoch time: 118.28 s 
2025-11-29 21:17:59.952765:  
2025-11-29 21:17:59.952868: Epoch 885 
2025-11-29 21:17:59.953024: Current learning rate: 0.00083 
2025-11-29 21:20:02.675529: train_loss -0.8395 
2025-11-29 21:20:02.682292: val_loss -0.8216 
2025-11-29 21:20:02.682417: Pseudo dice [np.float32(0.9513), np.float32(0.8864)] 
2025-11-29 21:20:02.683869: Epoch time: 122.73 s 
2025-11-29 21:20:03.544298:  
2025-11-29 21:20:03.544426: Epoch 886 
2025-11-29 21:20:03.544589: Current learning rate: 0.00079 
2025-11-29 21:22:01.617544: train_loss -0.8288 
2025-11-29 21:22:01.620285: val_loss -0.8527 
2025-11-29 21:22:01.620322: Pseudo dice [np.float32(0.9602), np.float32(0.9052)] 
2025-11-29 21:22:01.621263: Epoch time: 118.08 s 
2025-11-29 21:22:02.262658:  
2025-11-29 21:22:02.262774: Epoch 887 
2025-11-29 21:22:02.262836: Current learning rate: 0.00076 
2025-11-29 21:24:01.099444: train_loss -0.8392 
2025-11-29 21:24:01.106410: val_loss -0.8575 
2025-11-29 21:24:01.106531: Pseudo dice [np.float32(0.9604), np.float32(0.8867)] 
2025-11-29 21:24:01.108141: Epoch time: 118.84 s 
2025-11-29 21:24:01.985806:  
2025-11-29 21:24:01.985910: Epoch 888 
2025-11-29 21:24:01.986045: Current learning rate: 0.00073 
2025-11-29 21:25:59.932371: train_loss -0.8297 
2025-11-29 21:25:59.938995: val_loss -0.8264 
2025-11-29 21:25:59.939027: Pseudo dice [np.float32(0.9587), np.float32(0.9037)] 
2025-11-29 21:25:59.940612: Epoch time: 117.95 s 
2025-11-29 21:25:59.940753: Yayy! New best EMA pseudo Dice: 0.923799991607666 
2025-11-29 21:26:02.112071:  
2025-11-29 21:26:02.112183: Epoch 889 
2025-11-29 21:26:02.112254: Current learning rate: 0.0007 
2025-11-29 21:28:00.418826: train_loss -0.814 
2025-11-29 21:28:00.425374: val_loss -0.8087 
2025-11-29 21:28:00.425406: Pseudo dice [np.float32(0.9558), np.float32(0.8915)] 
2025-11-29 21:28:00.426959: Epoch time: 118.31 s 
2025-11-29 21:28:01.306855:  
2025-11-29 21:28:01.307409: Epoch 890 
2025-11-29 21:28:01.307555: Current learning rate: 0.00066 
2025-11-29 21:30:00.042616: train_loss -0.8163 
2025-11-29 21:30:00.049277: val_loss -0.838 
2025-11-29 21:30:00.049310: Pseudo dice [np.float32(0.9609), np.float32(0.904)] 
2025-11-29 21:30:00.050814: Epoch time: 118.74 s 
2025-11-29 21:30:00.050876: Yayy! New best EMA pseudo Dice: 0.9247000217437744 
2025-11-29 21:30:02.192225:  
2025-11-29 21:30:02.192371: Epoch 891 
2025-11-29 21:30:02.192430: Current learning rate: 0.00063 
2025-11-29 21:32:01.969877: train_loss -0.8116 
2025-11-29 21:32:01.975536: val_loss -0.8709 
2025-11-29 21:32:01.975744: Pseudo dice [np.float32(0.9649), np.float32(0.9145)] 
2025-11-29 21:32:01.977379: Epoch time: 119.78 s 
2025-11-29 21:32:01.977417: Yayy! New best EMA pseudo Dice: 0.9261999726295471 
2025-11-29 21:32:04.128429:  
2025-11-29 21:32:04.128555: Epoch 892 
2025-11-29 21:32:04.128620: Current learning rate: 0.0006 
2025-11-29 21:34:01.036924: train_loss -0.8312 
2025-11-29 21:34:01.043430: val_loss -0.8228 
2025-11-29 21:34:01.043578: Pseudo dice [np.float32(0.9559), np.float32(0.896)] 
2025-11-29 21:34:01.045162: Epoch time: 116.91 s 
2025-11-29 21:34:01.996376:  
2025-11-29 21:34:01.996495: Epoch 893 
2025-11-29 21:34:01.996646: Current learning rate: 0.00057 
2025-11-29 21:36:03.115079: train_loss -0.8265 
2025-11-29 21:36:03.121120: val_loss -0.8103 
2025-11-29 21:36:03.121151: Pseudo dice [np.float32(0.9597), np.float32(0.896)] 
2025-11-29 21:36:03.122559: Epoch time: 121.12 s 
2025-11-29 21:36:03.122622: Yayy! New best EMA pseudo Dice: 0.9262999892234802 
2025-11-29 21:36:05.131796:  
2025-11-29 21:36:05.131924: Epoch 894 
2025-11-29 21:36:05.131979: Current learning rate: 0.00054 
2025-11-29 21:38:04.979429: train_loss -0.8224 
2025-11-29 21:38:04.986090: val_loss -0.8312 
2025-11-29 21:38:04.986207: Pseudo dice [np.float32(0.9633), np.float32(0.9074)] 
2025-11-29 21:38:04.988024: Epoch time: 119.85 s 
2025-11-29 21:38:04.988085: Yayy! New best EMA pseudo Dice: 0.9272000193595886 
2025-11-29 21:38:10.966367:  
2025-11-29 21:38:10.966627: Epoch 895 
2025-11-29 21:38:10.966690: Current learning rate: 0.00052 
2025-11-29 21:40:08.456042: train_loss -0.8255 
2025-11-29 21:40:08.462548: val_loss -0.8286 
2025-11-29 21:40:08.462666: Pseudo dice [np.float32(0.9557), np.float32(0.8857)] 
2025-11-29 21:40:08.463666: Epoch time: 117.49 s 
2025-11-29 21:40:09.324428:  
2025-11-29 21:40:09.324505: Epoch 896 
2025-11-29 21:40:09.324642: Current learning rate: 0.00049 
2025-11-29 21:42:05.810296: train_loss -0.8328 
2025-11-29 21:42:05.816725: val_loss -0.8165 
2025-11-29 21:42:05.816843: Pseudo dice [np.float32(0.9586), np.float32(0.8873)] 
2025-11-29 21:42:05.818312: Epoch time: 116.49 s 
2025-11-29 21:42:06.743375:  
2025-11-29 21:42:06.743607: Epoch 897 
2025-11-29 21:42:06.743758: Current learning rate: 0.00046 
2025-11-29 21:44:05.402210: train_loss -0.8365 
2025-11-29 21:44:05.407243: val_loss -0.8236 
2025-11-29 21:44:05.407276: Pseudo dice [np.float32(0.9613), np.float32(0.9044)] 
2025-11-29 21:44:05.408370: Epoch time: 118.66 s 
2025-11-29 21:44:06.238234:  
2025-11-29 21:44:06.238577: Epoch 898 
2025-11-29 21:44:06.238642: Current learning rate: 0.00044 
2025-11-29 21:46:04.359561: train_loss -0.832 
2025-11-29 21:46:04.365820: val_loss -0.8269 
2025-11-29 21:46:04.365862: Pseudo dice [np.float32(0.961), np.float32(0.9096)] 
2025-11-29 21:46:04.367254: Epoch time: 118.12 s 
2025-11-29 21:46:04.367293: Yayy! New best EMA pseudo Dice: 0.9276999831199646 
2025-11-29 21:46:06.514424:  
2025-11-29 21:46:06.514493: Epoch 899 
2025-11-29 21:46:06.514541: Current learning rate: 0.00041 
2025-11-29 21:48:04.241539: train_loss -0.8195 
2025-11-29 21:48:04.248081: val_loss -0.8452 
2025-11-29 21:48:04.248199: Pseudo dice [np.float32(0.9586), np.float32(0.9016)] 
2025-11-29 21:48:04.249470: Epoch time: 117.73 s 
2025-11-29 21:48:05.728818: Yayy! New best EMA pseudo Dice: 0.9279999732971191 
2025-11-29 21:48:09.321097:  
2025-11-29 21:48:09.321203: Epoch 900 
2025-11-29 21:48:09.321259: Current learning rate: 0.00039 
2025-11-29 21:50:08.195624: train_loss -0.814 
2025-11-29 21:50:08.202905: val_loss -0.8476 
2025-11-29 21:50:08.203055: Pseudo dice [np.float32(0.9642), np.float32(0.9036)] 
2025-11-29 21:50:08.204529: Epoch time: 118.88 s 
2025-11-29 21:50:08.204636: Yayy! New best EMA pseudo Dice: 0.928600013256073 
2025-11-29 21:50:10.395507:  
2025-11-29 21:50:10.395612: Epoch 901 
2025-11-29 21:50:10.395672: Current learning rate: 0.00036 
2025-11-29 21:52:08.797176: train_loss -0.8367 
2025-11-29 21:52:08.803448: val_loss -0.8513 
2025-11-29 21:52:08.803479: Pseudo dice [np.float32(0.9574), np.float32(0.8896)] 
2025-11-29 21:52:08.805081: Epoch time: 118.4 s 
2025-11-29 21:52:09.714516:  
2025-11-29 21:52:09.714610: Epoch 902 
2025-11-29 21:52:09.714747: Current learning rate: 0.00034 
2025-11-29 21:54:07.134256: train_loss -0.8208 
2025-11-29 21:54:07.140687: val_loss -0.8599 
2025-11-29 21:54:07.140726: Pseudo dice [np.float32(0.9579), np.float32(0.8967)] 
2025-11-29 21:54:07.142243: Epoch time: 117.42 s 
2025-11-29 21:54:08.003110:  
2025-11-29 21:54:08.003219: Epoch 903 
2025-11-29 21:54:08.003381: Current learning rate: 0.00032 
2025-11-29 21:56:07.056020: train_loss -0.8265 
2025-11-29 21:56:07.062415: val_loss -0.81 
2025-11-29 21:56:07.062529: Pseudo dice [np.float32(0.9567), np.float32(0.8964)] 
2025-11-29 21:56:07.064056: Epoch time: 119.06 s 
2025-11-29 21:56:07.940300:  
2025-11-29 21:56:07.940419: Epoch 904 
2025-11-29 21:56:07.940509: Current learning rate: 0.0003 
2025-11-29 21:58:06.634380: train_loss -0.8307 
2025-11-29 21:58:06.640834: val_loss -0.8426 
2025-11-29 21:58:06.640949: Pseudo dice [np.float32(0.9631), np.float32(0.8982)] 
2025-11-29 21:58:06.642508: Epoch time: 118.7 s 
2025-11-29 21:58:11.515919:  
2025-11-29 21:58:11.516057: Epoch 905 
2025-11-29 21:58:11.516119: Current learning rate: 0.00028 
2025-11-29 22:00:10.016868: train_loss -0.8272 
2025-11-29 22:00:10.023550: val_loss -0.8456 
2025-11-29 22:00:10.023665: Pseudo dice [np.float32(0.9589), np.float32(0.8927)] 
2025-11-29 22:00:10.025037: Epoch time: 118.5 s 
2025-11-29 22:00:10.907011:  
2025-11-29 22:00:10.907121: Epoch 906 
2025-11-29 22:00:10.907264: Current learning rate: 0.00026 
2025-11-29 22:02:10.019462: train_loss -0.8294 
2025-11-29 22:02:10.026249: val_loss -0.8185 
2025-11-29 22:02:10.026336: Pseudo dice [np.float32(0.9613), np.float32(0.8959)] 
2025-11-29 22:02:10.027643: Epoch time: 119.12 s 
2025-11-29 22:02:10.958889:  
2025-11-29 22:02:10.959509: Epoch 907 
2025-11-29 22:02:10.959653: Current learning rate: 0.00024 
2025-11-29 22:04:08.838224: train_loss -0.8229 
2025-11-29 22:04:08.844831: val_loss -0.782 
2025-11-29 22:04:08.844950: Pseudo dice [np.float32(0.9596), np.float32(0.8911)] 
2025-11-29 22:04:08.846320: Epoch time: 117.88 s 
2025-11-29 22:04:09.787776:  
2025-11-29 22:04:09.787985: Epoch 908 
2025-11-29 22:04:09.788136: Current learning rate: 0.00022 
2025-11-29 22:06:09.734729: train_loss -0.8413 
2025-11-29 22:06:09.740928: val_loss -0.8256 
2025-11-29 22:06:09.741046: Pseudo dice [np.float32(0.9579), np.float32(0.8933)] 
2025-11-29 22:06:09.742481: Epoch time: 119.95 s 
2025-11-29 22:06:10.670547:  
2025-11-29 22:06:10.670647: Epoch 909 
2025-11-29 22:06:10.670794: Current learning rate: 0.00021 
2025-11-29 22:08:07.910909: train_loss -0.8374 
2025-11-29 22:08:07.916746: val_loss -0.8218 
2025-11-29 22:08:07.916862: Pseudo dice [np.float32(0.9572), np.float32(0.879)] 
2025-11-29 22:08:07.918265: Epoch time: 117.24 s 
2025-11-29 22:08:08.778025:  
2025-11-29 22:08:08.778548: Epoch 910 
2025-11-29 22:08:08.778694: Current learning rate: 0.00019 
2025-11-29 22:10:07.019398: train_loss -0.8154 
2025-11-29 22:10:07.025507: val_loss -0.8364 
2025-11-29 22:10:07.025624: Pseudo dice [np.float32(0.9583), np.float32(0.8984)] 
2025-11-29 22:10:07.026999: Epoch time: 118.24 s 
2025-11-29 22:10:07.845177:  
2025-11-29 22:10:07.845274: Epoch 911 
2025-11-29 22:10:07.845415: Current learning rate: 0.00017 
2025-11-29 22:12:05.836493: train_loss -0.8274 
2025-11-29 22:12:05.843585: val_loss -0.8126 
2025-11-29 22:12:05.843702: Pseudo dice [np.float32(0.9613), np.float32(0.889)] 
2025-11-29 22:12:05.845232: Epoch time: 117.99 s 
2025-11-29 22:12:06.706515:  
2025-11-29 22:12:06.706706: Epoch 912 
2025-11-29 22:12:06.706863: Current learning rate: 0.00016 
2025-11-29 22:14:04.672522: train_loss -0.822 
2025-11-29 22:14:04.680286: val_loss -0.8094 
2025-11-29 22:14:04.680428: Pseudo dice [np.float32(0.9641), np.float32(0.9099)] 
2025-11-29 22:14:04.681832: Epoch time: 117.97 s 
2025-11-29 22:14:05.557521:  
2025-11-29 22:14:05.557643: Epoch 913 
2025-11-29 22:14:05.557802: Current learning rate: 0.00015 
2025-11-29 22:16:04.980771: train_loss -0.8234 
2025-11-29 22:16:04.987456: val_loss -0.8301 
2025-11-29 22:16:04.987683: Pseudo dice [np.float32(0.9604), np.float32(0.901)] 
2025-11-29 22:16:04.989300: Epoch time: 119.43 s 
2025-11-29 22:16:05.854200:  
2025-11-29 22:16:05.854290: Epoch 914 
2025-11-29 22:16:05.854624: Current learning rate: 0.00013 
2025-11-29 22:18:05.010455: train_loss -0.8091 
2025-11-29 22:18:05.017322: val_loss -0.8445 
2025-11-29 22:18:05.017414: Pseudo dice [np.float32(0.9587), np.float32(0.8901)] 
2025-11-29 22:18:05.018823: Epoch time: 119.16 s 
2025-11-29 22:18:05.872927:  
2025-11-29 22:18:05.873044: Epoch 915 
2025-11-29 22:18:05.873194: Current learning rate: 0.00012 
2025-11-29 22:20:04.459760: train_loss -0.8216 
2025-11-29 22:20:04.466142: val_loss -0.8046 
2025-11-29 22:20:04.466257: Pseudo dice [np.float32(0.9603), np.float32(0.8875)] 
2025-11-29 22:20:04.467802: Epoch time: 118.59 s 
2025-11-29 22:20:05.358072:  
2025-11-29 22:20:05.358169: Epoch 916 
2025-11-29 22:20:05.358323: Current learning rate: 0.00011 
2025-11-29 22:22:07.671534: train_loss -0.8346 
2025-11-29 22:22:07.677675: val_loss -0.8559 
2025-11-29 22:22:07.677789: Pseudo dice [np.float32(0.9582), np.float32(0.898)] 
2025-11-29 22:22:07.679314: Epoch time: 122.32 s 
2025-11-29 22:22:08.598385:  
2025-11-29 22:22:08.598481: Epoch 917 
2025-11-29 22:22:08.598628: Current learning rate: 0.0001 
2025-11-29 22:24:06.790521: train_loss -0.8203 
2025-11-29 22:24:06.796796: val_loss -0.8104 
2025-11-29 22:24:06.796916: Pseudo dice [np.float32(0.9628), np.float32(0.9023)] 
2025-11-29 22:24:06.798409: Epoch time: 118.2 s 
2025-11-29 22:24:07.496755:  
2025-11-29 22:24:07.497109: Epoch 918 
2025-11-29 22:24:07.497353: Current learning rate: 9e-05 
2025-11-29 22:26:06.166205: train_loss -0.8202 
2025-11-29 22:26:06.172712: val_loss -0.8427 
2025-11-29 22:26:06.172834: Pseudo dice [np.float32(0.9601), np.float32(0.8953)] 
2025-11-29 22:26:06.174283: Epoch time: 118.67 s 
2025-11-29 22:26:07.046765:  
2025-11-29 22:26:07.046873: Epoch 919 
2025-11-29 22:26:07.047120: Current learning rate: 8e-05 
2025-11-29 22:28:06.119507: train_loss -0.8244 
2025-11-29 22:28:06.126237: val_loss -0.8291 
2025-11-29 22:28:06.126365: Pseudo dice [np.float32(0.9596), np.float32(0.8861)] 
2025-11-29 22:28:06.129591: Epoch time: 119.08 s 
2025-11-29 22:28:07.013324:  
2025-11-29 22:28:07.013554: Epoch 920 
2025-11-29 22:28:07.013778: Current learning rate: 7e-05 
2025-11-29 22:30:03.655879: train_loss -0.8298 
2025-11-29 22:30:03.662541: val_loss -0.8435 
2025-11-29 22:30:03.662665: Pseudo dice [np.float32(0.9614), np.float32(0.8998)] 
2025-11-29 22:30:03.664036: Epoch time: 116.65 s 
2025-11-29 22:30:04.584540:  
2025-11-29 22:30:04.584619: Epoch 921 
2025-11-29 22:30:04.584856: Current learning rate: 6e-05 
2025-11-29 22:32:05.855585: train_loss -0.832 
2025-11-29 22:32:05.862283: val_loss -0.8437 
2025-11-29 22:32:05.862558: Pseudo dice [np.float32(0.957), np.float32(0.891)] 
2025-11-29 22:32:05.863942: Epoch time: 121.28 s 
2025-11-29 22:32:06.726837:  
2025-11-29 22:32:06.726941: Epoch 922 
2025-11-29 22:32:06.727165: Current learning rate: 5e-05 
2025-11-29 22:34:05.807309: train_loss -0.8359 
2025-11-29 22:34:05.814008: val_loss -0.8641 
2025-11-29 22:34:05.814095: Pseudo dice [np.float32(0.9604), np.float32(0.9029)] 
2025-11-29 22:34:05.815537: Epoch time: 119.08 s 
2025-11-29 22:34:06.667016:  
2025-11-29 22:34:06.667111: Epoch 923 
2025-11-29 22:34:06.667340: Current learning rate: 4e-05 
2025-11-29 22:36:05.504976: train_loss -0.8295 
2025-11-29 22:36:05.511053: val_loss -0.8428 
2025-11-29 22:36:05.511260: Pseudo dice [np.float32(0.9586), np.float32(0.8872)] 
2025-11-29 22:36:05.512712: Epoch time: 118.84 s 
2025-11-29 22:36:06.385894:  
2025-11-29 22:36:06.386328: Epoch 924 
2025-11-29 22:36:06.386550: Current learning rate: 4e-05 
2025-11-29 22:38:04.544765: train_loss -0.8305 
2025-11-29 22:38:04.550963: val_loss -0.8469 
2025-11-29 22:38:04.551079: Pseudo dice [np.float32(0.955), np.float32(0.8806)] 
2025-11-29 22:38:04.552585: Epoch time: 118.16 s 
2025-11-29 22:38:05.412202:  
2025-11-29 22:38:05.412313: Epoch 925 
2025-11-29 22:38:05.412560: Current learning rate: 3e-05 
2025-11-29 22:40:02.557881: train_loss -0.8277 
2025-11-29 22:40:02.564915: val_loss -0.8074 
2025-11-29 22:40:02.565030: Pseudo dice [np.float32(0.9612), np.float32(0.8967)] 
2025-11-29 22:40:02.566463: Epoch time: 117.15 s 
2025-11-29 22:40:03.408174:  
2025-11-29 22:40:03.408334: Epoch 926 
2025-11-29 22:40:03.408555: Current learning rate: 3e-05 
2025-11-29 22:42:01.199291: train_loss -0.8421 
2025-11-29 22:42:01.206138: val_loss -0.8314 
2025-11-29 22:42:01.206264: Pseudo dice [np.float32(0.9663), np.float32(0.9103)] 
2025-11-29 22:42:01.207736: Epoch time: 117.79 s 
2025-11-29 22:42:02.093009:  
2025-11-29 22:42:02.093092: Epoch 927 
2025-11-29 22:42:02.093312: Current learning rate: 2e-05 
2025-11-29 22:44:04.521354: train_loss -0.8255 
2025-11-29 22:44:04.522983: val_loss -0.843 
2025-11-29 22:44:04.523014: Pseudo dice [np.float32(0.9603), np.float32(0.9075)] 
2025-11-29 22:44:04.524028: Epoch time: 122.43 s 
2025-11-29 22:44:05.064025:  
2025-11-29 22:44:05.064149: Epoch 928 
2025-11-29 22:44:05.064298: Current learning rate: 2e-05 
2025-11-29 22:46:03.671742: train_loss -0.8206 
2025-11-29 22:46:03.677893: val_loss -0.8583 
2025-11-29 22:46:03.678012: Pseudo dice [np.float32(0.9605), np.float32(0.9006)] 
2025-11-29 22:46:03.679384: Epoch time: 118.61 s 
2025-11-29 22:46:03.679526: Yayy! New best EMA pseudo Dice: 0.928600013256073 
2025-11-29 22:46:05.911926:  
2025-11-29 22:46:05.912037: Epoch 929 
2025-11-29 22:46:05.912195: Current learning rate: 1e-05 
2025-11-29 22:48:04.323407: train_loss -0.8367 
2025-11-29 22:48:04.326082: val_loss -0.8471 
2025-11-29 22:48:04.326203: Pseudo dice [np.float32(0.964), np.float32(0.9055)] 
2025-11-29 22:48:04.327310: Epoch time: 118.42 s 
2025-11-29 22:48:04.327334: Yayy! New best EMA pseudo Dice: 0.9291999936103821 
2025-11-29 22:48:07.730051:  
2025-11-29 22:48:07.730164: Epoch 930 
2025-11-29 22:48:07.730300: Current learning rate: 1e-05 
2025-11-29 22:50:05.162961: train_loss -0.8324 
2025-11-29 22:50:05.169309: val_loss -0.8032 
2025-11-29 22:50:05.169426: Pseudo dice [np.float32(0.9611), np.float32(0.8925)] 
2025-11-29 22:50:05.170820: Epoch time: 117.44 s 
2025-11-29 22:50:06.065540:  
2025-11-29 22:50:06.065648: Epoch 931 
2025-11-29 22:50:06.065880: Current learning rate: 1e-05 
2025-11-29 22:52:03.763988: train_loss -0.8325 
2025-11-29 22:52:03.770196: val_loss -0.8507 
2025-11-29 22:52:03.770229: Pseudo dice [np.float32(0.962), np.float32(0.9047)] 
2025-11-29 22:52:03.771520: Epoch time: 117.7 s 
2025-11-29 22:52:03.771633: Yayy! New best EMA pseudo Dice: 0.9294000267982483 
2025-11-29 22:52:07.193259:  
2025-11-29 22:52:07.193364: Epoch 932 
2025-11-29 22:52:07.193422: Current learning rate: 0.0 
2025-11-29 22:54:06.144792: train_loss -0.8224 
2025-11-29 22:54:06.150870: val_loss -0.8455 
2025-11-29 22:54:06.150984: Pseudo dice [np.float32(0.9636), np.float32(0.9038)] 
2025-11-29 22:54:06.152359: Epoch time: 118.95 s 
2025-11-29 22:54:06.152412: Yayy! New best EMA pseudo Dice: 0.9297999739646912 
2025-11-29 22:54:09.523704:  
2025-11-29 22:54:09.523829: Epoch 933 
2025-11-29 22:54:09.523898: Current learning rate: 0.0 
2025-11-29 22:56:08.178418: train_loss -0.8306 
2025-11-29 22:56:08.184493: val_loss -0.8297 
2025-11-29 22:56:08.184614: Pseudo dice [np.float32(0.9601), np.float32(0.9008)] 
2025-11-29 22:56:08.186061: Epoch time: 118.66 s 
2025-11-29 22:56:08.186151: Yayy! New best EMA pseudo Dice: 0.9298999905586243 
2025-11-29 22:56:10.328008:  
2025-11-29 22:56:10.328463: Epoch 934 
2025-11-29 22:56:10.328522: Current learning rate: 0.0 
2025-11-29 22:58:09.184542: train_loss -0.8289 
2025-11-29 22:58:09.190698: val_loss -0.8436 
2025-11-29 22:58:09.190814: Pseudo dice [np.float32(0.9668), np.float32(0.9039)] 
2025-11-29 22:58:09.192024: Epoch time: 118.86 s 
2025-11-29 22:58:09.192069: Yayy! New best EMA pseudo Dice: 0.930400013923645 
2025-11-29 22:58:12.639527:  
2025-11-29 22:58:12.639637: Epoch 935 
2025-11-29 22:58:12.639696: Current learning rate: 0.0 
2025-11-29 23:00:10.961205: train_loss -0.8262 
2025-11-29 23:00:10.967599: val_loss -0.8724 
2025-11-29 23:00:10.967727: Pseudo dice [np.float32(0.9608), np.float32(0.9178)] 
2025-11-29 23:00:10.969203: Epoch time: 118.32 s 
2025-11-29 23:00:10.969283: Yayy! New best EMA pseudo Dice: 0.9312999844551086 
2025-11-29 23:00:18.367299:  
2025-11-29 23:00:18.367389: Epoch 936 
2025-11-29 23:00:18.367471: Current learning rate: 0.0 
2025-11-29 23:02:17.841887: train_loss -0.8418 
2025-11-29 23:02:17.848049: val_loss -0.8642 
2025-11-29 23:02:17.848168: Pseudo dice [np.float32(0.9579), np.float32(0.8999)] 
2025-11-29 23:02:17.849438: Epoch time: 119.47 s 
2025-11-29 23:02:18.783001:  
2025-11-29 23:02:18.783088: Epoch 937 
2025-11-29 23:02:18.783232: Current learning rate: 0.0 
2025-11-29 23:04:17.306141: train_loss -0.8267 
2025-11-29 23:04:17.312881: val_loss -0.8337 
2025-11-29 23:04:17.312916: Pseudo dice [np.float32(0.9552), np.float32(0.8927)] 
2025-11-29 23:04:17.314348: Epoch time: 118.53 s 
2025-11-29 23:04:18.214350:  
2025-11-29 23:04:18.214488: Epoch 938 
2025-11-29 23:04:18.214633: Current learning rate: 0.0 
2025-11-29 23:06:16.709637: train_loss -0.8366 
2025-11-29 23:06:16.716352: val_loss -0.8405 
2025-11-29 23:06:16.716483: Pseudo dice [np.float32(0.9598), np.float32(0.8978)] 
2025-11-29 23:06:16.717899: Epoch time: 118.5 s 
2025-11-29 23:06:17.630264:  
2025-11-29 23:06:17.630438: Epoch 939 
2025-11-29 23:06:17.630586: Current learning rate: 0.0 
2025-11-29 23:08:16.252573: train_loss -0.811 
2025-11-29 23:08:16.259298: val_loss -0.8517 
2025-11-29 23:08:16.259423: Pseudo dice [np.float32(0.963), np.float32(0.8998)] 
2025-11-29 23:08:16.260892: Epoch time: 118.63 s 
2025-11-29 23:08:17.168770:  
2025-11-29 23:08:17.168871: Epoch 940 
2025-11-29 23:08:17.169017: Current learning rate: 0.0 
2025-11-29 23:10:14.266829: train_loss -0.8477 
2025-11-29 23:10:14.273102: val_loss -0.8253 
2025-11-29 23:10:14.273212: Pseudo dice [np.float32(0.9599), np.float32(0.9088)] 
2025-11-29 23:10:14.274701: Epoch time: 117.1 s 
2025-11-29 23:10:15.161217:  
2025-11-29 23:10:15.161331: Epoch 941 
2025-11-29 23:10:15.161505: Current learning rate: 0.0 
2025-11-29 23:12:15.435997: train_loss -0.8234 
2025-11-29 23:12:15.442426: val_loss -0.8195 
2025-11-29 23:12:15.442550: Pseudo dice [np.float32(0.9628), np.float32(0.9066)] 
2025-11-29 23:12:15.443885: Epoch time: 120.28 s 
2025-11-29 23:12:16.343257:  
2025-11-29 23:12:16.343692: Epoch 942 
2025-11-29 23:12:16.343938: Current learning rate: 1e-05 
2025-11-29 23:14:14.981792: train_loss -0.8118 
2025-11-29 23:14:14.987796: val_loss -0.8361 
2025-11-29 23:14:14.987916: Pseudo dice [np.float32(0.961), np.float32(0.9047)] 
2025-11-29 23:14:14.989381: Epoch time: 118.64 s 
2025-11-29 23:14:15.843433:  
2025-11-29 23:14:15.843544: Epoch 943 
2025-11-29 23:14:15.843779: Current learning rate: 1e-05 
2025-11-29 23:16:13.528718: train_loss -0.8346 
2025-11-29 23:16:13.534373: val_loss -0.8175 
2025-11-29 23:16:13.534493: Pseudo dice [np.float32(0.9563), np.float32(0.8953)] 
2025-11-29 23:16:13.535886: Epoch time: 117.69 s 
2025-11-29 23:16:14.430503:  
2025-11-29 23:16:14.430596: Epoch 944 
2025-11-29 23:16:14.430862: Current learning rate: 1e-05 
2025-11-29 23:18:13.796479: train_loss -0.8156 
2025-11-29 23:18:13.802825: val_loss -0.8277 
2025-11-29 23:18:13.802945: Pseudo dice [np.float32(0.954), np.float32(0.8779)] 
2025-11-29 23:18:13.804240: Epoch time: 119.37 s 
2025-11-29 23:18:14.691622:  
2025-11-29 23:18:14.692062: Epoch 945 
2025-11-29 23:18:14.692349: Current learning rate: 1e-05 
2025-11-29 23:20:13.089951: train_loss -0.8104 
2025-11-29 23:20:13.096461: val_loss -0.8392 
2025-11-29 23:20:13.096667: Pseudo dice [np.float32(0.9611), np.float32(0.9038)] 
2025-11-29 23:20:13.098210: Epoch time: 118.4 s 
2025-11-29 23:20:13.941241:  
2025-11-29 23:20:13.941356: Epoch 946 
2025-11-29 23:20:13.941589: Current learning rate: 2e-05 
2025-11-29 23:22:12.845069: train_loss -0.8026 
2025-11-29 23:22:12.851156: val_loss -0.8481 
2025-11-29 23:22:12.851188: Pseudo dice [np.float32(0.9622), np.float32(0.9021)] 
2025-11-29 23:22:12.852764: Epoch time: 118.91 s 
2025-11-29 23:22:13.696343:  
2025-11-29 23:22:13.696425: Epoch 947 
2025-11-29 23:22:13.696652: Current learning rate: 2e-05 
2025-11-29 23:24:16.910273: train_loss -0.817 
2025-11-29 23:24:16.916477: val_loss -0.8157 
2025-11-29 23:24:16.916594: Pseudo dice [np.float32(0.9571), np.float32(0.8926)] 
2025-11-29 23:24:16.917871: Epoch time: 123.22 s 
2025-11-29 23:24:17.827310:  
2025-11-29 23:24:17.827396: Epoch 948 
2025-11-29 23:24:17.827760: Current learning rate: 2e-05 
2025-11-29 23:26:14.794366: train_loss -0.8261 
2025-11-29 23:26:14.799968: val_loss -0.8331 
2025-11-29 23:26:14.800081: Pseudo dice [np.float32(0.9604), np.float32(0.8999)] 
2025-11-29 23:26:14.801270: Epoch time: 116.97 s 
2025-11-29 23:26:15.636871:  
2025-11-29 23:26:15.636968: Epoch 949 
2025-11-29 23:26:15.637107: Current learning rate: 2e-05 
2025-11-29 23:28:15.111263: train_loss -0.8421 
2025-11-29 23:28:15.117283: val_loss -0.8257 
2025-11-29 23:28:15.117317: Pseudo dice [np.float32(0.9635), np.float32(0.9083)] 
2025-11-29 23:28:15.118726: Epoch time: 119.48 s 
2025-11-29 23:28:20.244987:  
2025-11-29 23:28:20.245126: Epoch 950 
2025-11-29 23:28:20.245276: Current learning rate: 3e-05 
2025-11-29 23:30:19.638641: train_loss -0.835 
2025-11-29 23:30:19.641224: val_loss -0.8685 
2025-11-29 23:30:19.641342: Pseudo dice [np.float32(0.964), np.float32(0.9145)] 
2025-11-29 23:30:19.642590: Epoch time: 119.4 s 
2025-11-29 23:30:20.484551:  
2025-11-29 23:30:20.484712: Epoch 951 
2025-11-29 23:30:20.484887: Current learning rate: 3e-05 
2025-11-29 23:32:19.455033: train_loss -0.8234 
2025-11-29 23:32:19.461063: val_loss -0.7932 
2025-11-29 23:32:19.461181: Pseudo dice [np.float32(0.9597), np.float32(0.8995)] 
2025-11-29 23:32:19.462594: Epoch time: 118.97 s 
2025-11-29 23:32:20.352207:  
2025-11-29 23:32:20.352305: Epoch 952 
2025-11-29 23:32:20.352533: Current learning rate: 4e-05 
2025-11-29 23:34:18.711099: train_loss -0.827 
2025-11-29 23:34:18.717346: val_loss -0.8214 
2025-11-29 23:34:18.717462: Pseudo dice [np.float32(0.9603), np.float32(0.8934)] 
2025-11-29 23:34:18.719071: Epoch time: 118.36 s 
2025-11-29 23:34:19.650968:  
2025-11-29 23:34:19.651090: Epoch 953 
2025-11-29 23:34:19.651316: Current learning rate: 4e-05 
2025-11-29 23:36:18.672455: train_loss -0.828 
2025-11-29 23:36:18.678478: val_loss -0.819 
2025-11-29 23:36:18.678612: Pseudo dice [np.float32(0.9581), np.float32(0.8944)] 
2025-11-29 23:36:18.680135: Epoch time: 119.02 s 
2025-11-29 23:36:19.567170:  
2025-11-29 23:36:19.567255: Epoch 954 
2025-11-29 23:36:19.567477: Current learning rate: 4e-05 
2025-11-29 23:38:16.930133: train_loss -0.8429 
2025-11-29 23:38:16.936047: val_loss -0.8246 
2025-11-29 23:38:16.936172: Pseudo dice [np.float32(0.9585), np.float32(0.8938)] 
2025-11-29 23:38:16.937485: Epoch time: 117.37 s 
2025-11-29 23:38:17.791786:  
2025-11-29 23:38:17.791905: Epoch 955 
2025-11-29 23:38:17.792136: Current learning rate: 5e-05 
2025-11-29 23:40:16.200203: train_loss -0.8086 
2025-11-29 23:40:16.206055: val_loss -0.802 
2025-11-29 23:40:16.206090: Pseudo dice [np.float32(0.9587), np.float32(0.9014)] 
2025-11-29 23:40:16.207409: Epoch time: 118.41 s 
2025-11-29 23:40:17.099548:  
2025-11-29 23:40:17.099637: Epoch 956 
2025-11-29 23:40:17.099868: Current learning rate: 5e-05 
2025-11-29 23:42:15.114609: train_loss -0.8237 
2025-11-29 23:42:15.120410: val_loss -0.8127 
2025-11-29 23:42:15.120530: Pseudo dice [np.float32(0.9554), np.float32(0.8877)] 
2025-11-29 23:42:15.121948: Epoch time: 118.02 s 
2025-11-29 23:42:15.999982:  
2025-11-29 23:42:16.000070: Epoch 957 
2025-11-29 23:42:16.000299: Current learning rate: 5e-05 
2025-11-29 23:44:13.781069: train_loss -0.8168 
2025-11-29 23:44:13.786932: val_loss -0.8254 
2025-11-29 23:44:13.787019: Pseudo dice [np.float32(0.9574), np.float32(0.8996)] 
2025-11-29 23:44:13.788321: Epoch time: 117.78 s 
2025-11-29 23:44:18.696950:  
2025-11-29 23:44:18.697057: Epoch 958 
2025-11-29 23:44:18.697215: Current learning rate: 6e-05 
2025-11-29 23:46:17.268378: train_loss -0.8278 
2025-11-29 23:46:17.274857: val_loss -0.8046 
2025-11-29 23:46:17.274977: Pseudo dice [np.float32(0.9575), np.float32(0.894)] 
2025-11-29 23:46:17.276166: Epoch time: 118.57 s 
2025-11-29 23:46:18.186412:  
2025-11-29 23:46:18.186498: Epoch 959 
2025-11-29 23:46:18.186761: Current learning rate: 6e-05 
2025-11-29 23:48:16.520005: train_loss -0.8354 
2025-11-29 23:48:16.526570: val_loss -0.8518 
2025-11-29 23:48:16.526607: Pseudo dice [np.float32(0.9533), np.float32(0.8875)] 
2025-11-29 23:48:16.528161: Epoch time: 118.34 s 
2025-11-29 23:48:17.452235:  
2025-11-29 23:48:17.452839: Epoch 960 
2025-11-29 23:48:17.453063: Current learning rate: 7e-05 
2025-11-29 23:50:16.923958: train_loss -0.8378 
2025-11-29 23:50:16.930410: val_loss -0.8482 
2025-11-29 23:50:16.930527: Pseudo dice [np.float32(0.9593), np.float32(0.8961)] 
2025-11-29 23:50:16.932022: Epoch time: 119.47 s 
2025-11-29 23:50:17.820274:  
2025-11-29 23:50:17.820360: Epoch 961 
2025-11-29 23:50:17.820590: Current learning rate: 7e-05 
2025-11-29 23:52:17.205631: train_loss -0.8246 
2025-11-29 23:52:17.212364: val_loss -0.8292 
2025-11-29 23:52:17.212476: Pseudo dice [np.float32(0.9598), np.float32(0.8887)] 
2025-11-29 23:52:17.213888: Epoch time: 119.39 s 
2025-11-29 23:52:18.136038:  
2025-11-29 23:52:18.136148: Epoch 962 
2025-11-29 23:52:18.136370: Current learning rate: 7e-05 
2025-11-29 23:54:15.794970: train_loss -0.8254 
2025-11-29 23:54:15.800854: val_loss -0.8301 
2025-11-29 23:54:15.800891: Pseudo dice [np.float32(0.9558), np.float32(0.8962)] 
2025-11-29 23:54:15.802507: Epoch time: 117.66 s 
2025-11-29 23:54:16.631687:  
2025-11-29 23:54:16.632007: Epoch 963 
2025-11-29 23:54:16.632240: Current learning rate: 8e-05 
2025-11-29 23:56:14.639952: train_loss -0.8338 
2025-11-29 23:56:14.646310: val_loss -0.8395 
2025-11-29 23:56:14.646425: Pseudo dice [np.float32(0.9587), np.float32(0.8993)] 
2025-11-29 23:56:14.647889: Epoch time: 118.01 s 
2025-11-29 23:56:15.547039:  
2025-11-29 23:56:15.547541: Epoch 964 
2025-11-29 23:56:15.547772: Current learning rate: 8e-05 
2025-11-29 23:58:13.205320: train_loss -0.8074 
2025-11-29 23:58:13.211043: val_loss -0.8383 
2025-11-29 23:58:13.211156: Pseudo dice [np.float32(0.9567), np.float32(0.8967)] 
2025-11-29 23:58:13.212562: Epoch time: 117.66 s 
2025-11-29 23:58:14.120147:  
2025-11-29 23:58:14.120526: Epoch 965 
2025-11-29 23:58:14.120752: Current learning rate: 8e-05 
2025-11-30 00:00:11.849286: train_loss -0.8317 
2025-11-30 00:00:11.855405: val_loss -0.8247 
2025-11-30 00:00:11.855526: Pseudo dice [np.float32(0.9573), np.float32(0.8938)] 
2025-11-30 00:00:11.856986: Epoch time: 117.73 s 
2025-11-30 00:00:12.736018:  
2025-11-30 00:00:12.736127: Epoch 966 
2025-11-30 00:00:12.736366: Current learning rate: 9e-05 
2025-11-30 00:02:11.267043: train_loss -0.8363 
2025-11-30 00:02:11.273645: val_loss -0.8387 
2025-11-30 00:02:11.273761: Pseudo dice [np.float32(0.961), np.float32(0.9064)] 
2025-11-30 00:02:11.275119: Epoch time: 118.53 s 
2025-11-30 00:02:12.136668:  
2025-11-30 00:02:12.136776: Epoch 967 
2025-11-30 00:02:12.137005: Current learning rate: 9e-05 
2025-11-30 00:04:11.132326: train_loss -0.8223 
2025-11-30 00:04:11.138336: val_loss -0.8348 
2025-11-30 00:04:11.138457: Pseudo dice [np.float32(0.9606), np.float32(0.9008)] 
2025-11-30 00:04:11.139738: Epoch time: 119.0 s 
2025-11-30 00:04:12.020190:  
2025-11-30 00:04:12.020618: Epoch 968 
2025-11-30 00:04:12.020933: Current learning rate: 9e-05 
2025-11-30 00:06:09.264435: train_loss -0.8406 
2025-11-30 00:06:09.270637: val_loss -0.8698 
2025-11-30 00:06:09.270755: Pseudo dice [np.float32(0.958), np.float32(0.9064)] 
2025-11-30 00:06:09.272064: Epoch time: 117.25 s 
2025-11-30 00:06:10.126511:  
2025-11-30 00:06:10.126643: Epoch 969 
2025-11-30 00:06:10.126878: Current learning rate: 9e-05 
2025-11-30 00:08:12.265640: train_loss -0.83 
2025-11-30 00:08:12.271903: val_loss -0.8492 
2025-11-30 00:08:12.271943: Pseudo dice [np.float32(0.9634), np.float32(0.9103)] 
2025-11-30 00:08:12.273401: Epoch time: 122.14 s 
2025-11-30 00:08:13.147042:  
2025-11-30 00:08:13.147139: Epoch 970 
2025-11-30 00:08:13.147376: Current learning rate: 0.0001 
2025-11-30 00:10:12.434412: train_loss -0.8392 
2025-11-30 00:10:12.440737: val_loss -0.8453 
2025-11-30 00:10:12.440857: Pseudo dice [np.float32(0.9641), np.float32(0.9089)] 
2025-11-30 00:10:12.442072: Epoch time: 119.29 s 
2025-11-30 00:10:13.345466:  
2025-11-30 00:10:13.345565: Epoch 971 
2025-11-30 00:10:13.345730: Current learning rate: 0.0001 
2025-11-30 00:12:11.793119: train_loss -0.8269 
2025-11-30 00:12:11.800041: val_loss -0.8332 
2025-11-30 00:12:11.800155: Pseudo dice [np.float32(0.9623), np.float32(0.909)] 
2025-11-30 00:12:11.801533: Epoch time: 118.45 s 
2025-11-30 00:12:12.674943:  
2025-11-30 00:12:12.675097: Epoch 972 
2025-11-30 00:12:12.675255: Current learning rate: 0.0001 
2025-11-30 00:14:09.896307: train_loss -0.8125 
2025-11-30 00:14:09.902428: val_loss -0.8539 
2025-11-30 00:14:09.902548: Pseudo dice [np.float32(0.9661), np.float32(0.9224)] 
2025-11-30 00:14:09.903785: Epoch time: 117.22 s 
2025-11-30 00:14:09.903820: Yayy! New best EMA pseudo Dice: 0.9319999814033508 
2025-11-30 00:14:13.290069:  
2025-11-30 00:14:13.290239: Epoch 973 
2025-11-30 00:14:13.290293: Current learning rate: 0.0001 
2025-11-30 00:16:12.726010: train_loss -0.8238 
2025-11-30 00:16:12.732028: val_loss -0.8254 
2025-11-30 00:16:12.732061: Pseudo dice [np.float32(0.9595), np.float32(0.8969)] 
2025-11-30 00:16:12.733514: Epoch time: 119.44 s 
2025-11-30 00:16:13.636562:  
2025-11-30 00:16:13.636678: Epoch 974 
2025-11-30 00:16:13.636827: Current learning rate: 0.0001 
2025-11-30 00:18:11.782142: train_loss -0.8171 
2025-11-30 00:18:11.788594: val_loss -0.8332 
2025-11-30 00:18:11.788630: Pseudo dice [np.float32(0.9586), np.float32(0.8896)] 
2025-11-30 00:18:11.790079: Epoch time: 118.15 s 
2025-11-30 00:18:12.657508:  
2025-11-30 00:18:12.657588: Epoch 975 
2025-11-30 00:18:12.657725: Current learning rate: 0.0001 
2025-11-30 00:20:12.055915: train_loss -0.8352 
2025-11-30 00:20:12.062732: val_loss -0.8427 
2025-11-30 00:20:12.062891: Pseudo dice [np.float32(0.9615), np.float32(0.9045)] 
2025-11-30 00:20:12.064347: Epoch time: 119.4 s 
2025-11-30 00:20:12.957796:  
2025-11-30 00:20:12.957875: Epoch 976 
2025-11-30 00:20:12.958021: Current learning rate: 0.0001 
2025-11-30 00:22:11.972018: train_loss -0.8361 
2025-11-30 00:22:11.978379: val_loss -0.8438 
2025-11-30 00:22:11.978497: Pseudo dice [np.float32(0.9597), np.float32(0.8956)] 
2025-11-30 00:22:11.979804: Epoch time: 119.02 s 
2025-11-30 00:22:12.871758:  
2025-11-30 00:22:12.871878: Epoch 977 
2025-11-30 00:22:12.872028: Current learning rate: 0.0001 
2025-11-30 00:24:11.204112: train_loss -0.8207 
2025-11-30 00:24:11.210717: val_loss -0.8507 
2025-11-30 00:24:11.210834: Pseudo dice [np.float32(0.9593), np.float32(0.9035)] 
2025-11-30 00:24:11.212189: Epoch time: 118.34 s 
2025-11-30 00:24:12.081372:  
2025-11-30 00:24:12.081537: Epoch 978 
2025-11-30 00:24:12.081700: Current learning rate: 0.0001 
2025-11-30 00:26:10.345296: train_loss -0.8298 
2025-11-30 00:26:10.351973: val_loss -0.8271 
2025-11-30 00:26:10.352087: Pseudo dice [np.float32(0.9582), np.float32(0.903)] 
2025-11-30 00:26:10.353409: Epoch time: 118.27 s 
2025-11-30 00:26:11.245327:  
2025-11-30 00:26:11.245440: Epoch 979 
2025-11-30 00:26:11.245597: Current learning rate: 0.0001 
2025-11-30 00:28:10.191159: train_loss -0.8404 
2025-11-30 00:28:10.197628: val_loss -0.8079 
2025-11-30 00:28:10.197745: Pseudo dice [np.float32(0.9604), np.float32(0.8975)] 
2025-11-30 00:28:10.199078: Epoch time: 118.95 s 
2025-11-30 00:28:15.007051:  
2025-11-30 00:28:15.007177: Epoch 980 
2025-11-30 00:28:15.007228: Current learning rate: 0.0001 
2025-11-30 00:30:14.276496: train_loss -0.8238 
2025-11-30 00:30:14.282861: val_loss -0.8068 
2025-11-30 00:30:14.282903: Pseudo dice [np.float32(0.9579), np.float32(0.8958)] 
2025-11-30 00:30:14.284299: Epoch time: 119.27 s 
2025-11-30 00:30:15.197131:  
2025-11-30 00:30:15.197217: Epoch 981 
2025-11-30 00:30:15.197363: Current learning rate: 0.0001 
2025-11-30 00:32:13.850511: train_loss -0.8315 
2025-11-30 00:32:13.856691: val_loss -0.8484 
2025-11-30 00:32:13.856809: Pseudo dice [np.float32(0.9597), np.float32(0.8999)] 
2025-11-30 00:32:13.858333: Epoch time: 118.66 s 
2025-11-30 00:32:14.772520:  
2025-11-30 00:32:14.772590: Epoch 982 
2025-11-30 00:32:14.772727: Current learning rate: 0.0001 
2025-11-30 00:34:11.909181: train_loss -0.8187 
2025-11-30 00:34:11.915418: val_loss -0.851 
2025-11-30 00:34:11.915463: Pseudo dice [np.float32(0.9633), np.float32(0.9088)] 
2025-11-30 00:34:11.916731: Epoch time: 117.14 s 
2025-11-30 00:34:12.737744:  
2025-11-30 00:34:12.737859: Epoch 983 
2025-11-30 00:34:12.737976: Current learning rate: 0.0001 
2025-11-30 00:36:11.421994: train_loss -0.8303 
2025-11-30 00:36:11.428573: val_loss -0.8311 
2025-11-30 00:36:11.428694: Pseudo dice [np.float32(0.9615), np.float32(0.8942)] 
2025-11-30 00:36:11.430073: Epoch time: 118.69 s 
2025-11-30 00:36:12.335502:  
2025-11-30 00:36:12.335615: Epoch 984 
2025-11-30 00:36:12.335848: Current learning rate: 9e-05 
2025-11-30 00:38:10.675331: train_loss -0.8233 
2025-11-30 00:38:10.681345: val_loss -0.8515 
2025-11-30 00:38:10.681381: Pseudo dice [np.float32(0.9561), np.float32(0.8924)] 
2025-11-30 00:38:10.682669: Epoch time: 118.34 s 
2025-11-30 00:38:11.570943:  
2025-11-30 00:38:11.571046: Epoch 985 
2025-11-30 00:38:11.571276: Current learning rate: 9e-05 
2025-11-30 00:40:09.771031: train_loss -0.8234 
2025-11-30 00:40:09.777601: val_loss -0.8347 
2025-11-30 00:40:09.777718: Pseudo dice [np.float32(0.9591), np.float32(0.9068)] 
2025-11-30 00:40:09.779032: Epoch time: 118.2 s 
2025-11-30 00:40:10.657054:  
2025-11-30 00:40:10.657152: Epoch 986 
2025-11-30 00:40:10.657375: Current learning rate: 9e-05 
2025-11-30 00:42:08.657097: train_loss -0.83 
2025-11-30 00:42:08.664078: val_loss -0.8494 
2025-11-30 00:42:08.664111: Pseudo dice [np.float32(0.9632), np.float32(0.9101)] 
2025-11-30 00:42:08.665363: Epoch time: 118.0 s 
2025-11-30 00:42:09.565778:  
2025-11-30 00:42:09.565866: Epoch 987 
2025-11-30 00:42:09.566093: Current learning rate: 8e-05 
2025-11-30 00:44:08.022144: train_loss -0.8209 
2025-11-30 00:44:08.029002: val_loss -0.8403 
2025-11-30 00:44:08.029037: Pseudo dice [np.float32(0.9615), np.float32(0.9019)] 
2025-11-30 00:44:08.030458: Epoch time: 118.46 s 
2025-11-30 00:44:08.920090:  
2025-11-30 00:44:08.920206: Epoch 988 
2025-11-30 00:44:08.920443: Current learning rate: 8e-05 
2025-11-30 00:46:08.283298: train_loss -0.8344 
2025-11-30 00:46:08.290298: val_loss -0.8642 
2025-11-30 00:46:08.290344: Pseudo dice [np.float32(0.9625), np.float32(0.9068)] 
2025-11-30 00:46:08.291637: Epoch time: 119.37 s 
2025-11-30 00:46:09.185519:  
2025-11-30 00:46:09.185608: Epoch 989 
2025-11-30 00:46:09.185848: Current learning rate: 8e-05 
2025-11-30 00:48:08.406489: train_loss -0.8261 
2025-11-30 00:48:08.412927: val_loss -0.8437 
2025-11-30 00:48:08.413132: Pseudo dice [np.float32(0.9619), np.float32(0.9091)] 
2025-11-30 00:48:08.414556: Epoch time: 119.22 s 
2025-11-30 00:48:09.294440:  
2025-11-30 00:48:09.294580: Epoch 990 
2025-11-30 00:48:09.294813: Current learning rate: 7e-05 
2025-11-30 00:50:09.309207: train_loss -0.825 
2025-11-30 00:50:09.315413: val_loss -0.8092 
2025-11-30 00:50:09.315533: Pseudo dice [np.float32(0.956), np.float32(0.8861)] 
2025-11-30 00:50:09.316943: Epoch time: 120.02 s 
2025-11-30 00:50:14.233927:  
2025-11-30 00:50:14.234037: Epoch 991 
2025-11-30 00:50:14.234199: Current learning rate: 6e-05 
2025-11-30 00:52:11.995813: train_loss -0.8424 
2025-11-30 00:52:12.002231: val_loss -0.851 
2025-11-30 00:52:12.002347: Pseudo dice [np.float32(0.9612), np.float32(0.9069)] 
2025-11-30 00:52:12.003726: Epoch time: 117.76 s 
2025-11-30 00:52:12.894464:  
2025-11-30 00:52:12.894587: Epoch 992 
2025-11-30 00:52:12.894814: Current learning rate: 6e-05 
2025-11-30 00:54:11.856323: train_loss -0.8335 
2025-11-30 00:54:11.862830: val_loss -0.791 
2025-11-30 00:54:11.862865: Pseudo dice [np.float32(0.9593), np.float32(0.8908)] 
2025-11-30 00:54:11.864294: Epoch time: 118.96 s 
2025-11-30 00:54:12.779187:  
2025-11-30 00:54:12.779299: Epoch 993 
2025-11-30 00:54:12.779632: Current learning rate: 5e-05 
2025-11-30 00:56:10.993932: train_loss -0.831 
2025-11-30 00:56:11.000845: val_loss -0.8521 
2025-11-30 00:56:11.000959: Pseudo dice [np.float32(0.9588), np.float32(0.9065)] 
2025-11-30 00:56:11.002406: Epoch time: 118.22 s 
2025-11-30 00:56:11.898511:  
2025-11-30 00:56:11.898591: Epoch 994 
2025-11-30 00:56:11.898834: Current learning rate: 4e-05 
2025-11-30 00:58:09.186651: train_loss -0.8244 
2025-11-30 00:58:09.192592: val_loss -0.8585 
2025-11-30 00:58:09.192676: Pseudo dice [np.float32(0.9579), np.float32(0.9035)] 
2025-11-30 00:58:09.194002: Epoch time: 117.29 s 
2025-11-30 00:58:10.039915:  
2025-11-30 00:58:10.040270: Epoch 995 
2025-11-30 00:58:10.040498: Current learning rate: 4e-05 
2025-11-30 01:00:07.656958: train_loss -0.838 
2025-11-30 01:00:07.663423: val_loss -0.8153 
2025-11-30 01:00:07.663539: Pseudo dice [np.float32(0.957), np.float32(0.8976)] 
2025-11-30 01:00:07.664949: Epoch time: 117.62 s 
2025-11-30 01:00:08.563442:  
2025-11-30 01:00:08.563540: Epoch 996 
2025-11-30 01:00:08.563768: Current learning rate: 3e-05 
2025-11-30 01:02:07.522233: train_loss -0.8323 
2025-11-30 01:02:07.528376: val_loss -0.8555 
2025-11-30 01:02:07.528410: Pseudo dice [np.float32(0.9613), np.float32(0.9115)] 
2025-11-30 01:02:07.529745: Epoch time: 118.96 s 
2025-11-30 01:02:08.371903:  
2025-11-30 01:02:08.372422: Epoch 997 
2025-11-30 01:02:08.372646: Current learning rate: 2e-05 
2025-11-30 01:04:06.581753: train_loss -0.816 
2025-11-30 01:04:06.588356: val_loss -0.8237 
2025-11-30 01:04:06.588391: Pseudo dice [np.float32(0.961), np.float32(0.9003)] 
2025-11-30 01:04:06.589845: Epoch time: 118.21 s 
2025-11-30 01:04:07.451804:  
2025-11-30 01:04:07.451905: Epoch 998 
2025-11-30 01:04:07.452155: Current learning rate: 1e-05 
2025-11-30 01:06:06.277352: train_loss -0.8357 
2025-11-30 01:06:06.283993: val_loss -0.8368 
2025-11-30 01:06:06.284108: Pseudo dice [np.float32(0.9614), np.float32(0.9124)] 
2025-11-30 01:06:06.285591: Epoch time: 118.83 s 
2025-11-30 01:06:07.147268:  
2025-11-30 01:06:07.147358: Epoch 999 
2025-11-30 01:06:07.147525: Current learning rate: 0.0 
2025-11-30 01:08:05.657625: train_loss -0.8292 
2025-11-30 01:08:05.668970: val_loss -0.8359 
2025-11-30 01:08:05.669058: Pseudo dice [np.float32(0.9637), np.float32(0.8991)] 
2025-11-30 01:08:05.670558: Epoch time: 118.51 s 
2025-11-30 01:08:07.316701: Training done. 
2025-11-30 01:08:07.375972: predicting patient0051 
2025-11-30 01:08:07.779356: patient0051, shape torch.Size([1, 309, 507, 507]), rank 0 
2025-11-30 01:09:16.823727: predicting patient0052 
2025-11-30 01:09:17.265674: patient0052, shape torch.Size([1, 307, 520, 520]), rank 0 
2025-11-30 01:10:10.121314: predicting patient0053 
2025-11-30 01:10:10.384508: patient0053, shape torch.Size([1, 273, 481, 481]), rank 0 
2025-11-30 01:11:03.201694: predicting patient0054 
2025-11-30 01:11:03.578768: patient0054, shape torch.Size([1, 321, 569, 569]), rank 0 
2025-11-30 01:12:09.641153: predicting patient0055 
2025-11-30 01:12:10.060158: patient0055, shape torch.Size([1, 317, 577, 577]), rank 0 
2025-11-30 01:13:26.165929: predicting patient0056 
2025-11-30 01:13:26.376572: patient0056, shape torch.Size([1, 237, 455, 455]), rank 0 
2025-11-30 01:13:51.853973: predicting patient0057 
2025-11-30 01:13:52.212303: patient0057, shape torch.Size([1, 314, 551, 551]), rank 0 
2025-11-30 01:14:45.166542: predicting patient0058 
2025-11-30 01:14:45.417313: patient0058, shape torch.Size([1, 292, 455, 455]), rank 0 
2025-11-30 01:15:19.298376: predicting patient0059 
2025-11-30 01:15:19.514648: patient0059, shape torch.Size([1, 280, 450, 450]), rank 0 
2025-11-30 01:15:53.377910: predicting patient0060 
2025-11-30 01:15:53.757352: patient0060, shape torch.Size([1, 320, 551, 551]), rank 0 
2025-11-30 01:16:46.718860: predicting patient0061 
2025-11-30 01:16:46.955115: patient0061, shape torch.Size([1, 277, 484, 484]), rank 0 
2025-11-30 01:17:39.815638: predicting patient0062 
2025-11-30 01:17:40.112036: patient0062, shape torch.Size([1, 324, 502, 502]), rank 0 
2025-11-30 01:18:46.180642: predicting patient0063 
2025-11-30 01:18:46.453621: patient0063, shape torch.Size([1, 299, 502, 502]), rank 0 
2025-11-30 01:19:39.286291: predicting patient0064 
2025-11-30 01:19:39.620565: patient0064, shape torch.Size([1, 311, 551, 551]), rank 0 
2025-11-30 01:20:32.515699: predicting patient0065 
2025-11-30 01:20:32.839787: patient0065, shape torch.Size([1, 295, 540, 540]), rank 0 
2025-11-30 01:21:25.724934: predicting patient0066 
2025-11-30 01:21:26.068766: patient0066, shape torch.Size([1, 313, 548, 548]), rank 0 
2025-11-30 01:22:18.955520: predicting patient0067 
2025-11-30 01:22:19.215433: patient0067, shape torch.Size([1, 275, 471, 471]), rank 0 
2025-11-30 01:22:53.054680: predicting patient0068 
2025-11-30 01:22:53.308679: patient0068, shape torch.Size([1, 288, 484, 484]), rank 0 
2025-11-30 01:23:46.103852: predicting patient0069 
2025-11-30 01:23:46.315776: patient0069, shape torch.Size([1, 267, 465, 465]), rank 0 
2025-11-30 01:24:20.150350: predicting patient0070 
2025-11-30 01:24:20.478879: patient0070, shape torch.Size([1, 299, 551, 551]), rank 0 
2025-11-30 01:25:13.378386: predicting patient0071 
2025-11-30 01:25:13.693681: patient0071, shape torch.Size([1, 329, 499, 499]), rank 0 
2025-11-30 01:26:19.692756: predicting patient0072 
2025-11-30 01:26:20.017833: patient0072, shape torch.Size([1, 339, 502, 502]), rank 0 
2025-11-30 01:27:26.051939: predicting patient0073 
2025-11-30 01:27:26.342107: patient0073, shape torch.Size([1, 303, 504, 504]), rank 0 
2025-11-30 01:28:19.234622: predicting patient0074 
2025-11-30 01:28:19.589123: patient0074, shape torch.Size([1, 281, 587, 587]), rank 0 
2025-11-30 01:29:35.670236: predicting patient0075 
2025-11-30 01:29:36.043648: patient0075, shape torch.Size([1, 342, 530, 530]), rank 0 
2025-11-30 01:30:42.148635: predicting patient0076 
2025-11-30 01:30:42.483774: patient0076, shape torch.Size([1, 302, 587, 587]), rank 0 
2025-11-30 01:31:58.507711: predicting patient0077 
2025-11-30 01:31:58.818080: patient0077, shape torch.Size([1, 291, 455, 455]), rank 0 
2025-11-30 01:32:32.692446: predicting patient0078 
2025-11-30 01:32:33.174384: patient0078, shape torch.Size([1, 335, 512, 512]), rank 0 
2025-11-30 01:33:39.175531: predicting patient0079 
2025-11-30 01:33:39.543230: patient0079, shape torch.Size([1, 346, 540, 540]), rank 0 
2025-11-30 01:34:45.607531: predicting patient0080 
2025-11-30 01:34:45.856822: patient0080, shape torch.Size([1, 275, 455, 455]), rank 0 
2025-11-30 01:35:19.731329: predicting patient0081 
2025-11-30 01:35:20.043561: patient0081, shape torch.Size([1, 348, 484, 484]), rank 0 
2025-11-30 01:36:26.081329: predicting patient0082 
2025-11-30 01:36:26.407112: patient0082, shape torch.Size([1, 302, 551, 551]), rank 0 
2025-11-30 01:37:19.327783: predicting patient0083 
2025-11-30 01:37:19.708166: patient0083, shape torch.Size([1, 334, 551, 551]), rank 0 
2025-11-30 01:38:25.815599: predicting patient0084 
2025-11-30 01:38:26.139964: patient0084, shape torch.Size([1, 281, 538, 538]), rank 0 
2025-11-30 01:39:19.068971: predicting patient0085 
2025-11-30 01:39:19.496507: patient0085, shape torch.Size([1, 319, 634, 634]), rank 0 
2025-11-30 01:40:35.626285: predicting patient0086 
2025-11-30 01:40:35.953191: patient0086, shape torch.Size([1, 345, 484, 484]), rank 0 
2025-11-30 01:41:41.976660: predicting patient0087 
2025-11-30 01:41:42.243355: patient0087, shape torch.Size([1, 275, 496, 496]), rank 0 
2025-11-30 01:42:35.071600: predicting patient0088 
2025-11-30 01:42:35.328757: patient0088, shape torch.Size([1, 299, 481, 481]), rank 0 
2025-11-30 01:43:28.132393: predicting patient0089 
2025-11-30 01:43:28.417585: patient0089, shape torch.Size([1, 317, 484, 484]), rank 0 
2025-11-30 01:44:21.249834: predicting patient0090 
2025-11-30 01:44:21.504357: patient0090, shape torch.Size([1, 295, 465, 465]), rank 0 
2025-11-30 01:44:55.375965: predicting patient0091 
2025-11-30 01:44:55.776159: patient0091, shape torch.Size([1, 340, 584, 584]), rank 0 
2025-11-30 01:46:30.908588: predicting patient0092 
2025-11-30 01:46:31.201384: patient0092, shape torch.Size([1, 325, 465, 465]), rank 0 
2025-11-30 01:47:13.522441: predicting patient0093 
2025-11-30 01:47:13.825990: patient0093, shape torch.Size([1, 275, 551, 551]), rank 0 
2025-11-30 01:48:06.734967: predicting patient0094 
2025-11-30 01:48:07.018375: patient0094, shape torch.Size([1, 295, 499, 499]), rank 0 
2025-11-30 01:48:59.915627: predicting patient0095 
2025-11-30 01:49:00.306013: patient0095, shape torch.Size([1, 283, 623, 623]), rank 0 
2025-11-30 01:50:16.370450: predicting patient0096 
2025-11-30 01:50:16.618971: patient0096, shape torch.Size([1, 301, 455, 455]), rank 0 
2025-11-30 01:50:50.479638: predicting patient0097 
2025-11-30 01:50:50.773196: patient0097, shape torch.Size([1, 307, 515, 515]), rank 0 
2025-11-30 01:51:43.600824: predicting patient0098 
2025-11-30 01:51:43.987335: patient0098, shape torch.Size([1, 279, 634, 634]), rank 0 
2025-11-30 01:53:00.046163: predicting patient0099 
2025-11-30 01:53:00.397826: patient0099, shape torch.Size([1, 309, 551, 551]), rank 0 
2025-11-30 01:53:53.272106: predicting patient0100 
2025-11-30 01:53:53.515896: patient0100, shape torch.Size([1, 285, 481, 481]), rank 0 
2025-11-30 01:54:46.339689: predicting patient_001 
2025-11-30 01:54:46.694429: patient_001, shape torch.Size([1, 313, 569, 569]), rank 0 
2025-11-30 01:55:39.589674: predicting patient_002 
2025-11-30 01:55:39.985883: patient_002, shape torch.Size([1, 324, 577, 577]), rank 0 
2025-11-30 01:57:14.990098: predicting patient_003 
2025-11-30 01:57:15.302232: patient_003, shape torch.Size([1, 292, 543, 543]), rank 0 
2025-11-30 01:58:08.165804: predicting patient_004 
2025-11-30 01:58:08.422639: patient_004, shape torch.Size([1, 285, 484, 484]), rank 0 
2025-11-30 01:59:01.234766: predicting patient_005 
2025-11-30 01:59:01.454769: patient_005, shape torch.Size([1, 277, 465, 465]), rank 0 
2025-11-30 01:59:35.312654: predicting patient_006 
2025-11-30 01:59:35.590386: patient_006, shape torch.Size([1, 311, 465, 465]), rank 0 
2025-11-30 02:00:09.453788: predicting patient_007 
2025-11-30 02:00:09.673637: patient_007, shape torch.Size([1, 287, 453, 453]), rank 0 
2025-11-30 02:00:43.520523: predicting patient_008 
2025-11-30 02:00:43.730789: patient_008, shape torch.Size([1, 298, 450, 450]), rank 0 
2025-11-30 02:01:17.588497: predicting patient_009 
2025-11-30 02:01:17.913119: patient_009, shape torch.Size([1, 280, 561, 561]), rank 0 
2025-11-30 02:02:10.853086: predicting patient_010 
2025-11-30 02:02:11.051954: patient_010, shape torch.Size([1, 280, 445, 445]), rank 0 
2025-11-30 02:02:44.921900: predicting patient_013 
2025-11-30 02:02:45.129347: patient_013, shape torch.Size([1, 280, 458, 458]), rank 0 
2025-11-30 02:03:18.988803: predicting patient_014 
2025-11-30 02:03:19.278512: patient_014, shape torch.Size([1, 319, 502, 502]), rank 0 
2025-11-30 02:04:12.122480: predicting patient_015 
2025-11-30 02:04:12.508050: patient_015, shape torch.Size([1, 342, 587, 587]), rank 0 
2025-11-30 02:05:47.554964: predicting patient_016 
2025-11-30 02:05:47.907084: patient_016, shape torch.Size([1, 340, 551, 551]), rank 0 
2025-11-30 02:06:53.963635: predicting patient_018 
2025-11-30 02:06:54.285530: patient_018, shape torch.Size([1, 326, 489, 489]), rank 0 
2025-11-30 02:08:00.305007: predicting patient_019 
2025-11-30 02:08:00.590167: patient_019, shape torch.Size([1, 270, 538, 538]), rank 0 
2025-11-30 02:08:53.461366: predicting patient_020 
2025-11-30 02:08:53.962870: patient_020, shape torch.Size([1, 369, 512, 512]), rank 0 
2025-11-30 02:09:59.968393: predicting patient_021 
2025-11-30 02:10:00.206168: patient_021, shape torch.Size([1, 291, 465, 465]), rank 0 
2025-11-30 02:10:34.069160: predicting patient_022 
2025-11-30 02:10:34.410944: patient_022, shape torch.Size([1, 311, 561, 561]), rank 0 
2025-11-30 02:11:27.335134: predicting patient_023 
2025-11-30 02:11:27.679981: patient_023, shape torch.Size([1, 355, 515, 515]), rank 0 
2025-11-30 02:12:33.764932: predicting patient_024 
2025-11-30 02:12:34.141472: patient_024, shape torch.Size([1, 302, 595, 595]), rank 0 
2025-11-30 02:13:50.270573: predicting patient_025 
2025-11-30 02:13:50.516075: patient_025, shape torch.Size([1, 289, 481, 481]), rank 0 
2025-11-30 02:14:43.384311: predicting patient_026 
2025-11-30 02:14:43.706828: patient_026, shape torch.Size([1, 297, 561, 561]), rank 0 
2025-11-30 02:15:36.624130: predicting patient_027 
2025-11-30 02:15:36.928086: patient_027, shape torch.Size([1, 313, 499, 499]), rank 0 
2025-11-30 02:16:29.783229: predicting patient_028 
2025-11-30 02:16:30.108350: patient_028, shape torch.Size([1, 379, 465, 465]), rank 0 
2025-11-30 02:17:12.431700: predicting patient_029 
2025-11-30 02:17:12.750117: patient_029, shape torch.Size([1, 319, 546, 546]), rank 0 
2025-11-30 02:18:05.640253: predicting patient_030 
2025-11-30 02:18:05.899305: patient_030, shape torch.Size([1, 249, 458, 458]), rank 0 
2025-11-30 02:18:31.333756: predicting patient_033 
2025-11-30 02:18:31.597445: patient_033, shape torch.Size([1, 313, 491, 491]), rank 0 
2025-11-30 02:19:24.462784: predicting patient_034 
2025-11-30 02:19:24.797241: patient_034, shape torch.Size([1, 322, 551, 551]), rank 0 
2025-11-30 02:20:30.883095: predicting patient_037 
2025-11-30 02:20:31.202660: patient_037, shape torch.Size([1, 316, 551, 551]), rank 0 
2025-11-30 02:21:24.113933: predicting patient_038 
2025-11-30 02:21:24.347861: patient_038, shape torch.Size([1, 275, 455, 455]), rank 0 
2025-11-30 02:21:58.231550: predicting patient_039 
2025-11-30 02:21:58.562872: patient_039, shape torch.Size([1, 302, 551, 551]), rank 0 
2025-11-30 02:22:51.448472: predicting patient_040 
2025-11-30 02:22:51.616946: patient_040, shape torch.Size([1, 294, 385, 385]), rank 0 
2025-11-30 02:23:25.461159: predicting patient_041 
2025-11-30 02:23:25.797155: patient_041, shape torch.Size([1, 311, 551, 551]), rank 0 
2025-11-30 02:24:18.691293: predicting patient_042 
2025-11-30 02:24:19.228653: patient_042, shape torch.Size([1, 373, 680, 680]), rank 0 
2025-11-30 02:26:28.726200: predicting patient_043 
2025-11-30 02:26:29.095855: patient_043, shape torch.Size([1, 360, 530, 530]), rank 0 
2025-11-30 02:27:35.192561: predicting patient_044 
2025-11-30 02:27:35.517334: patient_044, shape torch.Size([1, 303, 551, 551]), rank 0 
2025-11-30 02:28:28.459018: predicting patient_045 
2025-11-30 02:28:28.809432: patient_045, shape torch.Size([1, 322, 569, 569]), rank 0 
2025-11-30 02:29:34.893156: predicting patient_048 
2025-11-30 02:29:35.170572: patient_048, shape torch.Size([1, 301, 507, 507]), rank 0 
2025-11-30 02:30:28.082061: predicting patient_049 
2025-11-30 02:30:28.406036: patient_049, shape torch.Size([1, 314, 551, 551]), rank 0 
